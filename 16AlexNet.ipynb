{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_PyTorch/blob/main/16AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "0_iHIjljeESi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # Original AlexNet uses kernel_size=11, stride=4 for 224x224 images.\n",
        "            # For 28x28, we need less aggressive downsampling.\n",
        "            nn.LazyConv2d(96, kernel_size=5, stride=1, padding=2), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            # Second convolutional layer\n",
        "            nn.LazyConv2d(256, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            # Remaining convolutional layers with smaller kernel size and stride\n",
        "            nn.LazyConv2d(384, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.LazyConv2d(384, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.LazyConv2d(256, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
        "            nn.LazyLinear(4096), nn.ReLU(),nn.Dropout(p=0.5),\n",
        "            nn.LazyLinear(num_classes))\n",
        "    def forward(self, X):\n",
        "      return self.net(X)"
      ],
      "metadata": {
        "id": "0gYgwcPkeIlA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlexNet()"
      ],
      "metadata": {
        "id": "3X5ZMKD8eMZn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "max_epochs = 3\n",
        "\n",
        "# Data loading\n",
        "transformer = transforms.ToTensor()\n",
        "mnist_train = datasets.FashionMNIST(root=\"../data\", train=True, transform=transformer, download=True)\n",
        "mnist_val = datasets.FashionMNIST(root=\"../data\", train=False, transform=transformer, download=True)\n",
        "\n",
        "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=4)\n",
        "val_iter = data.DataLoader(mnist_val, batch_size, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VglOd7H2ePuL",
        "outputId": "82240be9-5da0-48e2-caa1-e478e7ba4d4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.7MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 211kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.92MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 30.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "29f99ifgeTj7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(max_epochs):\n",
        "  model.train()\n",
        "  train_loss_sum, train_accuracy_sum, n = 0.0, 0.0, 0\n",
        "  for x, y in train_iter:\n",
        "    y_pred = model(x)\n",
        "    l = loss_fn(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    train_loss_sum += l\n",
        "    predicted_labels = torch.argmax(y_pred, dim=1)\n",
        "    train_accuracy_sum += (predicted_labels == y).float().sum()\n",
        "    n += y.numel()\n",
        "\n",
        "  model.eval()\n",
        "  test_accuracy_sum, test_n = 0.0, 0\n",
        "  with torch.no_grad():\n",
        "    for x, y in val_iter:\n",
        "      y_pred = model(x)\n",
        "      predicted_labels = torch.argmax(y_pred, dim=1)\n",
        "      test_accuracy_sum += (predicted_labels == y).float().sum()\n",
        "      test_n += y.numel()\n",
        "  test_accuracy = test_accuracy_sum / test_n\n",
        "  print(f'Epoch {epoch + 1}, Loss: {train_loss_sum / n:.4f}, Train Accuracy: {train_accuracy_sum / n:.4f}, Validation Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "y-Ppf2GfeWte"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "gpuType": "V5E1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_PyTorch/blob/main/00Preliminaries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "v2ELTsbnTHzU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(3).reshape((3, 1))\n",
        "b = torch.arange(2).reshape((1, 2))\n",
        "a, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTaTLCh9TBuj",
        "outputId": "49333330-5ecd-4312-a0ab-4bab311eff28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0],\n",
              "         [1],\n",
              "         [2]]),\n",
              " tensor([[0, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a + b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R3fJKIdTEH3",
        "outputId": "bcf0b967-fa34-4daa-b0dd-5f97233b5b28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('''NumRooms,RoofType,Price\n",
        "NA,NA,127500\n",
        "2,NA,106000\n",
        "4,Slate,178100\n",
        "NA,NA,140000''')"
      ],
      "metadata": {
        "id": "iBwhpTfjZIKM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(data_file)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z267-ZrgZS9L",
        "outputId": "90336240-e9f5-4177-dfbe-48957992900d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms RoofType   Price\n",
            "0       NaN      NaN  127500\n",
            "1       2.0      NaN  106000\n",
            "2       4.0    Slate  178100\n",
            "3       NaN      NaN  140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = data.iloc[:, 0:2], data.iloc[:, 2]\n",
        "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rftw0JuCbRpK",
        "outputId": "7a31ae90-f6aa-415f-ae3e-f7a796ee5119"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms  RoofType_Slate  RoofType_nan\n",
            "0       NaN           False          True\n",
            "1       2.0           False          True\n",
            "2       4.0            True         False\n",
            "3       NaN           False          True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.arange(6).reshape(6, 1)\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj9zlemsq_1F",
        "outputId": "29265051-36a8-4742-ff3b-b635fa11b9fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [1],\n",
              "        [2],\n",
              "        [3],\n",
              "        [4],\n",
              "        [5]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2\n",
        "X = torch.arange(24).reshape(2, 3, 4)\n",
        "a + X, (a * X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfoz8upfwEQo",
        "outputId": "c4815e9d-ca69-4aa7-8ab7-8dd1269ed6c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 2,  3,  4,  5],\n",
              "          [ 6,  7,  8,  9],\n",
              "          [10, 11, 12, 13]],\n",
              " \n",
              "         [[14, 15, 16, 17],\n",
              "          [18, 19, 20, 21],\n",
              "          [22, 23, 24, 25]]]),\n",
              " tensor([[[ 0,  2,  4,  6],\n",
              "          [ 8, 10, 12, 14],\n",
              "          [16, 18, 20, 22]],\n",
              " \n",
              "         [[24, 26, 28, 30],\n",
              "          [32, 34, 36, 38],\n",
              "          [40, 42, 44, 46]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
        "B = A.clone()  # Assign a copy of A to B by allocating new memory\n",
        "A, A + B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWxuf2Djyv0z",
        "outputId": "bca734ce-ddf0-4689-b6ff-4a969cc8eae5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 1., 2.],\n",
              "         [3., 4., 5.]]),\n",
              " tensor([[ 0.,  2.,  4.],\n",
              "         [ 6.,  8., 10.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape, A.sum(axis=0).shape, A.sum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXKlsTNWy3OB",
        "outputId": "8422d404-5438-4096-d78f-ccfce7a60532"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.Size([3]), tensor([3., 5., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape, A.sum(axis=1).shape, A.sum(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR3L57nszJK0",
        "outputId": "389bd6da-ea49-4dd9-9ef3-5e26c2d2c86a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.Size([2]), tensor([ 3., 12.]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.sum(axis=[0, 1])  # Same as A.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4TOHAXb0JAO",
        "outputId": "b1047713-15d5-4574-ab13-10c256259182"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "c8smCU8VHj3b"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define a function f for which you want to calculate the numerical limit.\n",
        "# For example, let's define f(x) = x**2\n",
        "def f(x):\n",
        "    return x**2\n",
        "\n",
        "for h in 10.0**np.arange(-1, -6, -1):\n",
        "    print(f'h={h:.5f}, numerical limit={(f(1+h)-f(1))/h:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRpVUeaiHgYl",
        "outputId": "963b728d-db26-46a9-d9c3-848967d0b0cf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h=0.10000, numerical limit=2.10000\n",
            "h=0.01000, numerical limit=2.01000\n",
            "h=0.00100, numerical limit=2.00100\n",
            "h=0.00010, numerical limit=2.00010\n",
            "h=0.00001, numerical limit=2.00001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(4.0)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34wQiWUmQXk0",
        "outputId": "823d9ef1-c405-4476-db01-a7fefb107220"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, requires_grad_() is a method used to change the requires_grad attribute of an existing tensor in-place. When a tensor has requires_grad=True, PyTorch will track all operations on it to enable automatic differentiation (autograd). This is crucial for training neural networks, as it allows PyTorch to compute gradients of a loss function with respect to the model's parameters.\n",
        "\n",
        "Here's how it works and why you'd use it:\n",
        "\n",
        "Tracking History: If requires_grad is True, PyTorch builds a computational graph for every operation performed on that tensor. This graph records how the output was computed from the inputs.\n",
        "Gradient Computation: Later, when you call .backward() on a scalar output that depends on this tensor, PyTorch uses this computational graph to automatically calculate the gradients of the output with respect to the tensor (and any other tensors in the graph that require_grad=True).\n",
        "In-Place Modification: The underscore (_) in requires_grad_ indicates that it's an in-place operation, meaning it modifies the tensor directly rather than returning a new one. This is often more memory-efficient.\n",
        "Example:\n",
        "\n",
        "Imagine you have a tensor x:\n",
        "\n",
        "x = torch.tensor([1., 2., 3.])\n",
        "\n",
        "By default, x.requires_grad would be False. If you then calculate y = x * x, no gradient information would be stored, and you wouldn't be able to call y.backward() to find dy/dx.\n",
        "\n",
        "However, if you do:\n",
        "\n",
        "x = torch.tensor([1., 2., 3.]) x.requires_grad_(True)\n",
        "\n",
        "Now, x.requires_grad is True. If you then proceed with calculations like:\n",
        "\n",
        "y = 2 * torch.dot(x, x) (similar to one of the examples in your notebook)\n",
        "\n",
        "PyTorch will track all these operations. When you call y.backward(), it will compute the gradients of y with respect to x, and these gradients will be stored in x.grad."
      ],
      "metadata": {
        "id": "m0QO-O4O3vca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also create x = torch.arange(4.0, requires_grad=True)\n",
        "x.requires_grad_(True)\n",
        "x.grad  # The gradient is None by default"
      ],
      "metadata": {
        "id": "uGpVfvuTQabo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = 2 * torch.dot(x, x)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9x4gRQGQdcJ",
        "outputId": "3ecd487d-2508-4c64-eae0-5d045d89cffc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(28., grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value of x.grad is calculated through PyTorch's automatic differentiation mechanism, specifically after calling y.backward(). This operation computes the gradient of y with respect to x.\n",
        "\n",
        "Let's break it down:\n",
        "\n",
        "Define x and y:\n",
        "\n",
        "x = torch.arange(4.0) results in x = tensor([0., 1., 2., 3.]).\n",
        "y = 2 * torch.dot(x, x)\n",
        "Expand y: If x = [x_0, x_1, x_2, x_3], then torch.dot(x, x) is x_0^2 + x_1^2 + x_2^2 + x_3^2. So, y = 2 * (x_0^2 + x_1^2 + x_2^2 + x_3^2).\n",
        "\n",
        "Calculate the Partial Derivatives (Gradients): To get x.grad, PyTorch computes the partial derivative of y with respect to each component of x (dy/dx_i):\n",
        "\n",
        "dy/dx_0 = d/dx_0 [2 * (x_0^2 + x_1^2 + x_2^2 + x_3^2)] = 2 * (2 * x_0) = 4 * x_0\n",
        "dy/dx_1 = d/dx_1 [2 * (x_0^2 + x_1^2 + x_2^2 + x_3^2)] = 2 * (2 * x_1) = 4 * x_1\n",
        "dy/dx_2 = d/dx_2 [2 * (x_0^2 + x_1^2 + x_2^2 + x_3^2)] = 2 * (2 * x_2) = 4 * x_2\n",
        "dy/dx_3 = d/dx_3 [2 * (x_0^2 + x_1^2 + x_2^2 + x_3^2)] = 2 * (2 * x_3) = 4 * x_3\n",
        "Substitute x values: Now, substitute the values from x = tensor([0., 1., 2., 3.]) into these derivatives:\n",
        "\n",
        "4 * 0. = 0.\n",
        "4 * 1. = 4.\n",
        "4 * 2. = 8.\n",
        "4 * 3. = 12.\n",
        "This results in x.grad being tensor([0., 4., 8., 12.])."
      ],
      "metadata": {
        "id": "9PeCcPNISY2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D9_xUdLRL1F",
        "outputId": "13efd78d-9cf9-4f51-d960-ace11de51bc1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  4.,  8., 12.])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad == 4 * x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgyEuxFlSi71",
        "outputId": "d468a2e9-59a5-43d3-f2d4-73e86c34d3cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The x.grad value is [1., 1., 1., 1.] in the last block because of the following steps:\n",
        "\n",
        "x.grad.zero_(): This line explicitly resets the gradients accumulated from previous backward() calls to zero. Before this, x.grad was [0., 4., 8., 12.].\n",
        "\n",
        "y = x.sum(): The variable y is redefined to be the sum of all elements in x.\n",
        "\n",
        "x = tensor([0., 1., 2., 3.])\n",
        "So, y = 0. + 1. + 2. + 3. = 6.\n",
        "y.backward(): This triggers the computation of gradients of the new y (which is x.sum()) with respect to x. The chain rule is applied.\n",
        "\n",
        "If y = x_0 + x_1 + x_2 + x_3,\n",
        "Then the partial derivative dy/dx_0 = 1\n",
        "dy/dx_1 = 1\n",
        "dy/dx_2 = 1\n",
        "dy/dx_3 = 1\n",
        "Since x.grad was reset to zero before this backward() call, the newly computed gradients ([1., 1., 1., 1.]) are assigned to x.grad."
      ],
      "metadata": {
        "id": "YmannpOTTnU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()  # Reset the gradient\n",
        "y = x.sum()\n",
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdWQ8B16TQeF",
        "outputId": "c89eb66b-f286-4408-cf83-de5487d4e44d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's break down how x.grad became [0., 2., 4., 6.] in that last code block:\n",
        "\n",
        "x.grad.zero_(): First, any previously accumulated gradients in x.grad are reset to zero. This ensures that we are calculating fresh gradients for the new y definition.\n",
        "\n",
        "y = x * x: Here, y is redefined. Unlike the previous examples where y was a scalar (2 * torch.dot(x,x) or x.sum()), this operation performs an element-wise multiplication. So, y becomes a tensor of the same shape as x:\n",
        "\n",
        "x = tensor([0., 1., 2., 3.])\n",
        "y[0] = 0. * 0. = 0.\n",
        "y[1] = 1. * 1. = 1.\n",
        "y[2] = 2. * 2. = 4.\n",
        "y[3] = 3. * 3. = 9. So, y = tensor([0., 1., 4., 9.]).\n",
        "y.backward(gradient=torch.ones(len(y))): When y is a non-scalar tensor (like a vector or matrix), y.backward() requires a gradient argument. This argument is a tensor of the same shape as y, and it represents the gradient of the 'overall output' (which y contributes to) with respect to y.\n",
        "\n",
        "In this case, gradient=torch.ones(len(y)) means gradient=tensor([1., 1., 1., 1.]). This effectively tells PyTorch to consider the sum of y as the final scalar output for which we want gradients.\n",
        "For each element y_i = x_i^2, the derivative dy_i/dx_i is 2 * x_i.\n",
        "Since the gradient argument is [1., 1., 1., 1.], the final gradient x.grad_i is effectively 1 * (2 * x_i).\n",
        "Let's apply this:\n",
        "\n",
        "For x[0] = 0.: x.grad[0] = 2 * 0. = 0.\n",
        "For x[1] = 1.: x.grad[1] = 2 * 1. = 2.\n",
        "For x[2] = 2.: x.grad[2] = 2 * 2. = 4.\n",
        "For x[3] = 3.: x.grad[3] = 2 * 3. = 6.\n",
        "This results in x.grad = tensor([0., 2., 4., 6.]).\n",
        "\n",
        "The comment # Faster: y.sum().backward() is a shortcut that achieves the same result, as y.sum().backward() implicitly uses torch.ones_like(y) as the gradient argument."
      ],
      "metadata": {
        "id": "gW7E-a2uV8u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "y.backward(gradient=torch.ones(len(y)))  # Faster: y.sum().backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EUsmVvuU-uG",
        "outputId": "0fe5700a-03fd-4b73-b0ef-80c161ddc875"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The .detach() method in PyTorch is used to create a new tensor that shares the same storage with the original tensor but does not track its history of operations. In simple terms, it removes the tensor from the computational graph, making it a constant for subsequent operations with respect to gradient calculations.\n",
        "\n",
        "Let's break it down in the context of your code:\n",
        "\n",
        "y = x * x: Here, y is computed based on x, so PyTorch tracks this operation to compute gradients later.\n",
        "u = y.detach(): This is where detach() comes in.\n",
        "u gets the value of y (which is tensor([0., 1., 4., 9.])).\n",
        "However, u is detached from the computational graph that connects y back to x. This means that any operation involving u will treat u as a constant, not as something whose value depends on x through y.\n",
        "z = u * x: Now, z is calculated by multiplying u and x element-wise.\n",
        "When z.sum().backward() is called, PyTorch calculates the gradients of z.sum() with respect to x.\n",
        "Since u was detached, it's treated as a constant during this gradient calculation. So, if z_i = u_i * x_i, then the derivative dz_i/dx_i is simply u_i (because u_i is treated as a constant coefficient).\n",
        "Therefore, after z.sum().backward(), x.grad will be equal to u because u acts as the gradient of z with respect to x when u itself is not considered a function of x."
      ],
      "metadata": {
        "id": "dQxXIyuTYVJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "u = y.detach()\n",
        "z = u * x\n",
        "\n",
        "z.sum().backward()\n",
        "x.grad == u"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEI8reVQXqxd",
        "outputId": "ab3eda8b-cd1f-4122-91ff-b6a051e9881c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()\n",
        "y.sum().backward()\n",
        "x.grad == 2 * x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VCe1M6yYcE-",
        "outputId": "4dc6ebba-0873-4366-cd0c-87fba51b8773"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(a):\n",
        "    b = a * 2\n",
        "    while b.norm() < 1000:\n",
        "        b = b * 2\n",
        "    if b.sum() > 0:\n",
        "        c = b\n",
        "    else:\n",
        "        c = 100 * b\n",
        "    return c"
      ],
      "metadata": {
        "id": "_qw2ZCAVdCCn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(size=(), requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()"
      ],
      "metadata": {
        "id": "Yc7uGCTbdFQS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad, a.grad == d / a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvJ1WgOqdIAX",
        "outputId": "65395cd3-3171-48cd-ce2d-dbee10d8abf0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1024.), tensor(True))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probability"
      ],
      "metadata": {
        "id": "Khsb-ei6f6oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "from torch.distributions.multinomial import Multinomial"
      ],
      "metadata": {
        "id": "wJBLgVNdgR4i"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tosses = 100\n",
        "heads = sum([random.random() > 0.5 for _ in range(num_tosses)])\n",
        "tails = num_tosses - heads\n",
        "print(\"heads, tails: \", [heads, tails])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unwglFVof_AS",
        "outputId": "6dc231a9-e5f7-49e3-fe13-fb565b1e6a09"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heads, tails:  [54, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's break down Multinomial(100, fair_probs).sample() with an everyday example.\n",
        "\n",
        "Imagine you're flipping a fair coin 100 times.\n",
        "\n",
        "Multinomial: This refers to a [redacted link]. It's a generalization of the binomial distribution, used when there are more than two possible outcomes (like rolling a multi-sided die) or for multiple trials of a binary outcome (like many coin flips).\n",
        "\n",
        "100: This is the total_count parameter. In our coin-flipping example, this is the total number of times you're going to flip the coin (100 flips).\n",
        "\n",
        "fair_probs = torch.tensor([0.5, 0.5]): This is the probs parameter, representing the probabilities of each possible outcome. Since fair_probs is [0.5, 0.5], it means:\n",
        "\n",
        "The first outcome (let's say 'Heads') has a 50% chance (0.5).\n",
        "The second outcome (let's say 'Tails') also has a 50% chance (0.5). This perfectly describes a fair coin.\n",
        ".sample(): This method tells the distribution to generate one random outcome based on the given probabilities and total count.\n",
        "\n",
        "Putting it together (Example):\n",
        "\n",
        "When you run Multinomial(100, fair_probs).sample(), PyTorch simulates 100 fair coin flips and then tells you how many times each outcome ('Heads' and 'Tails') occurred.\n",
        "\n",
        "For instance, the output tensor([46., 54.]) from your notebook means that out of 100 coin flips, the simulation resulted in:\n",
        "\n",
        "46 'Heads' (the first element, corresponding to the first probability in fair_probs)\n",
        "54 'Tails' (the second element, corresponding to the second probability in fair_probs)\n",
        "Notice that the sum 46 + 54 = 100, which equals the total_count you specified. Each time you call .sample(), you'll likely get slightly different numbers (e.g., [52, 48], [49, 51]), but their sum will always be 100."
      ],
      "metadata": {
        "id": "HIGImpXXiL-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fair_probs = torch.tensor([0.5, 0.5])\n",
        "Multinomial(100, fair_probs).sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX1ZJA05g9sp",
        "outputId": "310f94c2-c81a-4ead-bb0d-de47b067630c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([43., 57.])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Multinomial(100, fair_probs).sample() / 100"
      ],
      "metadata": {
        "id": "3-my4Ro1ikra",
        "outputId": "f0e44706-d6ef-44e6-f8e6-29161c8ce223",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5300, 0.4700])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = Multinomial(10000, fair_probs).sample()\n",
        "counts / 10000"
      ],
      "metadata": {
        "id": "dpaoKPhQi_j-",
        "outputId": "259cdb6b-6b50-42fb-c01c-fce39e0af673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5089, 0.4911])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! In the code, counts represents the outcome of 10,000 individual coin flips (or more generally, multinomial trials). Each 'coin flip' here has two possible outcomes, heads or tails, with equal probability (0.5 for heads, 0.5 for tails), as defined by fair_probs = torch.tensor([0.5, 0.5]) and Multinomial(1, fair_probs). The (10000,) part in .sample((10000,)) means we are simulating this process 10,000 times.\n",
        "\n",
        "Since each individual flip can either be heads (represented as [1., 0.]) or tails (represented as [0., 1.]), counts will be a tensor with 10,000 rows and 2 columns. Each row will look like either [1., 0.] (meaning a head was flipped) or [0., 1.] (meaning a tail was flipped).\n",
        "\n",
        "For example, if you were to look at the first few rows of counts, you might see something like:\n",
        "\n",
        "[[0., 1.], (First flip was a tail) [1., 0.], (Second flip was a head) [1., 0.], (Third flip was a head) [0., 1.], (Fourth flip was a tail) ... ]\n",
        "\n",
        "Each row indicates the outcome of a single trial, where the first column tracks heads and the second column tracks tails."
      ],
      "metadata": {
        "id": "8e_3pARmDyX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------"
      ],
      "metadata": {
        "id": "6VCxkpH2E0Dt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Following counts, cum_counts stands for 'cumulative counts'. It's generated by applying the cumsum(dim=0) operation to counts.\n",
        "\n",
        "cumsum(dim=0) calculates the cumulative sum along the first dimension (rows). This means that for each flip (row), it sums up all the 'heads' and 'tails' encountered up to and including that flip.\n",
        "\n",
        "Let's use the previous counts example:\n",
        "\n",
        "If counts was: [[0., 1.], (Flip 1: 0 heads, 1 tail) [1., 0.], (Flip 2: 1 head, 0 tails) [1., 0.], (Flip 3: 1 head, 0 tails) [0., 1.]] (Flip 4: 0 heads, 1 tail)\n",
        "\n",
        "Then cum_counts would become:\n",
        "\n",
        "After Flip 1: [0., 1.] (0 heads, 1 tail total)\n",
        "After Flip 2: [0.+1., 1.+0.] = [1., 1.] (1 head, 1 tail total)\n",
        "After Flip 3: [1.+1., 1.+0.] = [2., 1.] (2 heads, 1 tail total)\n",
        "After Flip 4: [2.+0., 1.+1.] = [2., 2.] (2 heads, 2 tails total)\n",
        "So, cum_counts would be: [[0., 1.], [1., 1.], [2., 1.], [2., 2.]]\n",
        "\n",
        "Each row in cum_counts tells you the total number of heads and tails that have occurred from the very beginning up to that specific coin flip in the sequence."
      ],
      "metadata": {
        "id": "4wc-xCAEE2QQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------"
      ],
      "metadata": {
        "id": "m6qbHQK5F79y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Following cum_counts, estimates represents the estimated probability of each outcome (heads or tails) at each step of the simulation. It's calculated by taking the cum_counts and dividing each cumulative count by the total number of samples taken up to that point.\n",
        "\n",
        "Specifically, estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True) means:\n",
        "\n",
        "cum_counts.sum(dim=1, keepdims=True) calculates the total number of flips that have occurred up to each row. For example, after 1 flip, the sum is 1; after 2 flips, the sum is 2, and so on.\n",
        "By dividing cum_counts (which has the cumulative number of heads and tails) by this running total, we get the proportion of heads and tails observed so far.\n",
        "Let's continue with our previous example where cum_counts was: [[0., 1.], [1., 1.], [2., 1.], [2., 2.]]\n",
        "\n",
        "And the cumulative sums of flips (from cum_counts.sum(dim=1, keepdims=True)) would be: [[1.], [2.], [3.], [4.]]\n",
        "\n",
        "Then estimates would be calculated as:\n",
        "\n",
        "After Flip 1: [0./1., 1./1.] = [0., 1.] (0% heads, 100% tails)\n",
        "After Flip 2: [1./2., 1./2.] = [0.5, 0.5] (50% heads, 50% tails)\n",
        "After Flip 3: [2./3., 1./3.] = [0.6667, 0.3333] (66.7% heads, 33.3% tails)\n",
        "After Flip 4: [2./4., 2./4.] = [0.5, 0.5] (50% heads, 50% tails)\n",
        "So, estimates would be: [[0., 1.], [0.5, 0.5], [0.6667, 0.3333], [0.5, 0.5]]\n",
        "\n",
        "Each row in estimates shows the current estimated probability of getting heads (first column) or tails (second column) based on all the flips that have occurred up to that point."
      ],
      "metadata": {
        "id": "H8MhWsGVF9OO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "counts = Multinomial(1, fair_probs).sample((10000,))\n",
        "print(counts)\n",
        "cum_counts = counts.cumsum(dim=0)\n",
        "print(cum_counts)\n",
        "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
        "print(estimates)\n",
        "estimates = estimates.numpy()\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (4.5, 3.5)\n",
        "plt.plot(estimates[:, 0], label=(\"P(coin=heads)\"))\n",
        "plt.plot(estimates[:, 1], label=(\"P(coin=tails)\"))\n",
        "plt.axhline(y=0.5, color='black', linestyle='dashed')\n",
        "plt.gca().set_xlabel('Samples')\n",
        "plt.gca().set_ylabel('Estimated probability')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "Ne-_niz4BhxB",
        "outputId": "be08f80c-7554-4731-ed11-c5e41a973678"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        ...,\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.]])\n",
            "tensor([[1.0000e+00, 0.0000e+00],\n",
            "        [2.0000e+00, 0.0000e+00],\n",
            "        [3.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [5.0820e+03, 4.9160e+03],\n",
            "        [5.0830e+03, 4.9160e+03],\n",
            "        [5.0830e+03, 4.9170e+03]])\n",
            "tensor([[1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.5083, 0.4917],\n",
            "        [0.5084, 0.4916],\n",
            "        [0.5083, 0.4917]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 450x350 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(torch.ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aHd1FXCqRu3",
        "outputId": "2aef616e-9c6c-4b8a-dc45-815ee4050d21"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on built-in function ones in module torch:\n",
            "\n",
            "ones(...)\n",
            "    ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
            "\n",
            "    Returns a tensor filled with the scalar value `1`, with the shape defined\n",
            "    by the variable argument :attr:`size`.\n",
            "\n",
            "    Args:\n",
            "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
            "            Can be a variable number of arguments or a collection like a list or tuple.\n",
            "\n",
            "    Keyword arguments:\n",
            "        out (Tensor, optional): the output tensor.\n",
            "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "            Default: if ``None``, uses a global default (see :func:`torch.set_default_dtype`).\n",
            "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
            "            Default: ``torch.strided``.\n",
            "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            "            Default: if ``None``, uses the current device for the default tensor type\n",
            "            (see :func:`torch.set_default_device`). :attr:`device` will be the CPU\n",
            "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
            "        requires_grad (bool, optional): If autograd should record operations on the\n",
            "            returned tensor. Default: ``False``.\n",
            "\n",
            "    Example::\n",
            "\n",
            "        >>> torch.ones(2, 3)\n",
            "        tensor([[ 1.,  1.,  1.],\n",
            "                [ 1.,  1.,  1.]])\n",
            "\n",
            "        >>> torch.ones(5)\n",
            "        tensor([ 1.,  1.,  1.,  1.,  1.])\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
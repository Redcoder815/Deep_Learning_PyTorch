{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_PyTorch/blob/main/22ResNetAndResNext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils import data\n",
        "from torchvision import datasets\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "Pvav1yv8nuEu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF5oB-DP6HRR",
        "outputId": "90dad6ef-6f48-4477-cce8-4ba224f074a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module):\n",
        "    \"\"\"The Residual block of ResNet models.\"\"\"\n",
        "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
        "                                   stride=strides)\n",
        "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                       stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.bn1 = nn.LazyBatchNorm2d()\n",
        "        self.bn2 = nn.LazyBatchNorm2d()\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)"
      ],
      "metadata": {
        "id": "0D27VH3Gn11x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = Residual(3)\n",
        "X = torch.randn(4, 3, 6, 6)\n",
        "blk(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4rwkEY6oBXM",
        "outputId": "1b29514b-77c8-441c-d9d1-28fdd067c42a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When use_1x1conv=True and strides=2, the output shape is torch.Size([4, 6, 3, 3]) due to the following:\n",
        "\n",
        "Batch Size and Output Channels: The first two dimensions 4 and 6 correspond to the batch size of the input X (which is 4) and the num_channels specified in the Residual block constructor (which is 6).\n",
        "\n",
        "Spatial Dimensions (Height and Width):\n",
        "\n",
        "Both the main convolutional path (conv1) and the shortcut path (conv3) apply a stride of 2. A stride of 2 effectively halves the spatial dimensions (height and width) of the input feature map.\n",
        "The input spatial dimensions are 6x6.\n",
        "For a convolutional layer, the output spatial dimension can be calculated as floor((Input_Dim - Kernel_Size + 2 * Padding) / Stride) + 1.\n",
        "For self.conv1 (kernel_size=3, padding=1, stride=2): floor((6 - 3 + 2*1) / 2) + 1 = floor(5 / 2) + 1 = 2 + 1 = 3. So, the height and width become 3x3.\n",
        "For self.conv3 (kernel_size=1, padding=0 by default for 1x1, stride=2): floor((6 - 1 + 2*0) / 2) + 1 = floor(5 / 2) + 1 = 2 + 1 = 3. So, the height and width become 3x3.\n",
        "Since both paths result in a 6-channel, 3x3 feature map, they can be added together, and the final output retains this shape."
      ],
      "metadata": {
        "id": "fr78QCZSrWPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------"
      ],
      "metadata": {
        "id": "I8oXTemMsSF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's a good question! Let's break down self.conv2:\n",
        "\n",
        "self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1):\n",
        "\n",
        "It also outputs num_channels (which is 6 in the example).\n",
        "It has a kernel_size=3 and padding=1.\n",
        "Crucially, if strides is not specified, it defaults to 1.\n",
        "When kernel_size=3, padding=1, and stride=1, the convolutional layer preserves the spatial dimensions of its input.\n",
        "\n",
        "The output from self.conv1 (after ReLU and BatchNorm) is 4, 6, 3, 3. When this passes through self.conv2, its dimensions remain 3x3. So, self.conv2 takes an input of 3x3 spatial dimensions and outputs 3x3 spatial dimensions.\n",
        "\n",
        "In summary, self.conv1 (with strides=2) reduces the spatial dimensions from 6x6 to 3x3. self.conv2 then processes this 3x3 feature map but does not further change its spatial dimensions because its stride is 1. Therefore, the output of the main path (self.conv2(F.relu(self.bn1(self.conv1(X))))) and the shortcut path (self.conv3(X)) both have the spatial dimensions 3x3, allowing them to be added together."
      ],
      "metadata": {
        "id": "MAmYxDtLsUOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------"
      ],
      "metadata": {
        "id": "2H01xTPMs2AO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're right to ask for that clarification! Let's re-emphasize the first two dimensions of the torch.Size([4, 6, 3, 3]) output:\n",
        "\n",
        "The 4 (Batch Size): This first dimension directly corresponds to the batch size of your input tensor X. When you defined X = torch.randn(4, 3, 6, 6), the 4 specified that there are 4 independent samples in the batch. This dimension is preserved throughout the network unless an operation explicitly changes it (e.g., a batch-wise aggregation).\n",
        "\n",
        "The 6 (Output Channels): This second dimension comes from the num_channels parameter you passed to the Residual block constructor. In your example, you created blk = Residual(6, use_1x1conv=True, strides=2). The 6 here dictates that both self.conv1, self.conv2, and self.conv3 (if use_1x1conv is True) will output 6 feature channels. The Residual block is designed to maintain the number of channels specified by num_channels as its output feature depth.\n",
        "\n",
        "So, torch.Size([batch_size, num_channels, height, width]) is torch.Size([4, 6, 3, 3]) because:\n",
        "\n",
        "4 is your input batch size.\n",
        "6 is the num_channels you set in Residual(6, ...).\n",
        "3x3 are the spatial dimensions after the strided convolutions, as we discussed."
      ],
      "metadata": {
        "id": "h5is8Js2s63F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blk = Residual(6, use_1x1conv=True, strides=2)\n",
        "blk(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Coz-XLLVo2tT",
        "outputId": "2fb584a0-4bbc-44f0-dd02-027ed8d9a5aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 6, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Let's break down the line self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0))) from the ResNet class:\n",
        "\n",
        "self.net: This refers to the nn.Sequential container that makes up the main body of your ResNet model. It was initialized earlier with self.net = nn.Sequential(self.b1()).\n",
        ".add_module(name, module): This is a method available for nn.Module (and thus for nn.Sequential). It's used to add a new child module to the self.net sequential container, giving it a specific name.\n",
        "f'b{i+2}': This is the name given to the new module being added. It's an f-string that dynamically generates a name for each block of residual layers. For example, when i=0, the name will be 'b2' (since self.b1() is already added as 'b1'). When i=1, it will be 'b3', and so on.\n",
        "self.block(*b, first_block=(i==0)): This is the actual module that is being added. It calls the self.block method (defined within your ResNet class) to construct a sequence of Residual layers. Let's look at its arguments:\n",
        "*b: The arch parameter in the ResNet constructor is expected to be a list of tuples (e.g., [(2, 64), (2, 128)]). Each tuple b contains two values: num_residuals (number of residual layers in this block) and num_channels (number of output channels for these layers). The *b syntax unpacks this tuple so that self.block receives these as separate arguments: self.block(num_residuals, num_channels, ...). For example, if b = (2, 64), it calls self.block(2, 64, ...).\n",
        "first_block=(i==0): This is a boolean flag passed to self.block. It evaluates to True only for the very first iteration of the loop (i=0). This flag is crucial within the self.block method to determine if the first Residual layer in that particular block should perform downsampling (by setting use_1x1conv=True and strides=2) or not. This is a common pattern in ResNet to downsample the feature map at the beginning of certain blocks.\n",
        "In summary: This line of code iteratively adds blocks of Residual layers to the ResNet model. Each block is named sequentially (e.g., b2, b3), and the first Residual layer within each new block (except the very first block overall) might perform spatial downsampling based on the first_block flag to gradually reduce the feature map size while increasing the number of channels."
      ],
      "metadata": {
        "id": "XlASubIY0ND8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------"
      ],
      "metadata": {
        "id": "ugtqabFb2e0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "blk.append(Residual(num_channels, use_1x1conv=True, strides=2)):\n",
        "\n",
        "This line of code is found within the block method of your ResNet class. It's responsible for creating and adding a specific type of Residual block to a list (blk), which will then form part of the larger nn.Sequential block.\n",
        "\n",
        "Here's what each part signifies:\n",
        "\n",
        "blk.append(...): This means you're adding an instance of a Residual module to the list blk. The block method aggregates several Residual layers into a single nn.Sequential module.\n",
        "\n",
        "Residual(num_channels, use_1x1conv=True, strides=2):\n",
        "\n",
        "num_channels: This argument specifies the number of output channels for the convolutional layers within this particular Residual block. For example, if num_channels is 64, then self.conv1, self.conv2, and self.conv3 (if used) inside this Residual instance will all output 64 channels.\n",
        "use_1x1conv=True: This is a crucial parameter. When set to True, it tells the Residual block to employ a 1x1 convolution in its shortcut path (the self.conv3 in your Residual class). This 1x1 convolution serves two main purposes in ResNet:\n",
        "Channel Matching: If the main path of the residual block changes the number of channels (which it often does in ResNet stages), the 1x1 convolution in the shortcut path ensures that the number of channels matches between the input X and the output Y of the main path, so they can be added together (Y += X).\n",
        "Spatial Downsampling: When combined with strides > 1 (as in this case), the 1x1 convolution in the shortcut path also performs spatial downsampling.\n",
        "strides=2: This parameter further defines the behavior of the Residual block. When strides=2 is used in conjunction with use_1x1conv=True (which it is here):\n",
        "The first convolutional layer in the main path (self.conv1) will use a stride of 2, effectively halving the spatial dimensions (height and width) of the feature map.\n",
        "The 1x1 convolution in the shortcut path (self.conv3) will also use a stride of 2, ensuring that its output also has halved spatial dimensions, matching the output of the main path.\n",
        "In summary: This specific line creates a Residual block that is designed to change the number of channels to num_channels and simultaneously reduce the spatial dimensions of the feature map by half. This is typically used at the beginning of a new stage in a ResNet architecture to downsample the feature maps while increasing their depth (number of channels)."
      ],
      "metadata": {
        "id": "ejSny2zY2geO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------"
      ],
      "metadata": {
        "id": "dB2lDhFo3Fq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's a great question for clarification! No, the line blk.append(Residual(num_channels, use_1x1conv=True, strides=2)) itself does not directly use or call the forward method of the Residual module.\n",
        "\n",
        "Here's why:\n",
        "\n",
        "Instantiation (__init__): When you write Residual(...), you are creating an instance of the Residual class. At this point, the __init__ method of the Residual class is called. This method is responsible for setting up the layers (conv1, conv2, bn1, bn2, conv3) and their configurations (like num_channels, kernel_size, strides).\n",
        "Execution (forward): The forward method of a PyTorch nn.Module is called implicitly when you pass an input tensor through an instance of that module. For example, if you had my_residual_block = Residual(...), then output = my_residual_block(input_tensor) would cause the forward method to be executed.\n",
        "So, the blk.append(...) line is involved in constructing the network by adding a configured Residual block. The forward method of that Residual block will only be called later, when data is actually passed through the entire ResNet model (which contains this blk as part of its self.net sequential container)."
      ],
      "metadata": {
        "id": "TqN7GDxU3Gxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------"
      ],
      "metadata": {
        "id": "0eKkM8Db5lXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's an excellent question to understand how the architecture is constructed! Let's break down how i and b take values from arch and how *b works in self.block.\n",
        "\n",
        "How i and b get values from arch (for i, b in enumerate(arch):)\n",
        "\n",
        "arch is a list of tuples, for example, ((2, 64), (2, 128), (2, 256), (2, 512)). Each tuple represents a 'stage' or 'block' of residual layers in the ResNet.\n",
        "enumerate(arch): This built-in Python function is used to iterate over a sequence (like arch) while also keeping track of the index of each item. It yields pairs of (index, item).\n",
        "for i, b in enumerate(arch):\n",
        "In each iteration of the loop, i receives the current index.\n",
        "b receives the current item (which is one of the tuples from arch).\n",
        "Let's trace it:\n",
        "\n",
        "First iteration: i will be 0, and b will be (2, 64).\n",
        "Second iteration: i will be 1, and b will be (2, 128).\n",
        "And so on, for each tuple in arch.\n",
        "How *b passes values to self.block (self.block(*b, ...) )\n",
        "\n",
        "You defined self.block to accept arguments like this: def block(self, num_residuals, num_channels, first_block=False):\n",
        "The * (asterisk) operator before b is called the unpacking operator.\n",
        "When you use *b in a function call, it takes the elements of the iterable b (which is a tuple in this case) and unpacks them as separate, positional arguments to the function.\n",
        "Let's use our example values:\n",
        "\n",
        "When b is (2, 64) (from the first iteration):\n",
        "\n",
        "self.block(*b, ...) effectively becomes self.block(2, 64, ...).\n",
        "So, num_residuals inside self.block will be 2, and num_channels will be 64.\n",
        "When b is (2, 128) (from the second iteration):\n",
        "\n",
        "self.block(*b, ...) effectively becomes self.block(2, 128, ...).\n",
        "So, num_residuals inside self.block will be 2, and num_channels will be 128.\n",
        "In essence, enumerate provides both the count (i) and the architectural tuple (b), and the *b syntax conveniently passes the components of that tuple directly as arguments to the block method, allowing you to define the number of residual layers and channels for each stage of your ResNet."
      ],
      "metadata": {
        "id": "oC9qa3as5myN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, arch, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(self.b1())\n",
        "        for i, b in enumerate(arch):\n",
        "            self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
        "        self.net.add_module('last', nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes)))\n",
        "\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def block(self, num_residuals, num_channels, first_block=False):\n",
        "        blk = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "            else:\n",
        "                blk.append(Residual(num_channels))\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.net(X)"
      ],
      "metadata": {
        "id": "wd4lt2hCuBZk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(ResNet):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)),\n",
        "                       num_classes)"
      ],
      "metadata": {
        "id": "-hIUYBSK3QwY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YZGsEC94MFf",
        "outputId": "7970fb9f-7afb-4790-b62a-bb59d460b8c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet18(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): LazyConv2d(0, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "      (1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (b2): Sequential(\n",
              "      (0): Residual(\n",
              "        (conv1): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (conv1): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (b3): Sequential(\n",
              "      (0): Residual(\n",
              "        (conv1): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (conv1): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (b4): Sequential(\n",
              "      (0): Residual(\n",
              "        (conv1): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv2): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): LazyConv2d(0, 256, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (conv1): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (b5): Sequential(\n",
              "      (0): Residual(\n",
              "        (conv1): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv2): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv3): LazyConv2d(0, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (conv1): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (last): Sequential(\n",
              "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (1): Flatten(start_dim=1, end_dim=-1)\n",
              "      (2): LazyLinear(in_features=0, out_features=10, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256"
      ],
      "metadata": {
        "id": "NN5hMxR36enx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ],
      "metadata": {
        "id": "Z9hxi10K6h4X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = datasets.FashionMNIST(root=\"../data\", train=True, transform=Transform, download=True)\n",
        "mnist_val = datasets.FashionMNIST(root=\"../data\", train=False, transform=Transform, download=True)\n",
        "\n",
        "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=2)\n",
        "val_iter = data.DataLoader(mnist_val, batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUBoMugR6l37",
        "outputId": "effc6711-daaa-48fb-b054-e1ee714063d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 111MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 3.69MB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 58.3MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 4.00MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "pSZJ8v3x6qzy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 3"
      ],
      "metadata": {
        "id": "WPtTfM6i6uUo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(max_epochs):\n",
        "  model.train()\n",
        "  train_loss_sum, train_accuracy_sum, n = 0.0, 0.0, 0\n",
        "  for images, labels in train_iter:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    y_pred = model(images)\n",
        "    l = criterion(y_pred, labels)\n",
        "    optimizer.zero_grad()\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    train_loss_sum += l\n",
        "    predicted_labels = torch.argmax(y_pred, dim=1)\n",
        "    train_accuracy_sum += (predicted_labels == labels).float().sum()\n",
        "    n += labels.numel()\n",
        "\n",
        "  model.eval()\n",
        "  test_accuracy_sum, test_n = 0.0, 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in val_iter:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      y_pred = model(images)\n",
        "      predicted_labels = torch.argmax(y_pred, dim=1)\n",
        "      test_accuracy_sum += (predicted_labels == labels).float().sum()\n",
        "      test_n += labels.numel()\n",
        "  test_accuracy = test_accuracy_sum / test_n\n",
        "  print(f'Epoch {epoch + 1}, Loss: {train_loss_sum / n:.4f}, Train Accuracy: {train_accuracy_sum / n:.4f}, Validation Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw0kiwZ460Jq",
        "outputId": "ab8e1534-1652-49c6-cc7e-09269b358fd4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.0022, Train Accuracy: 0.7973, Validation Accuracy: 0.8231\n",
            "Epoch 2, Loss: 0.0012, Train Accuracy: 0.8914, Validation Accuracy: 0.8833\n",
            "Epoch 3, Loss: 0.0009, Train Accuracy: 0.9132, Validation Accuracy: 0.9045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNeXtBlock(nn.Module):\n",
        "    \"\"\"The ResNeXt block.\"\"\"\n",
        "    def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False,\n",
        "                 strides=1):\n",
        "        super().__init__()\n",
        "        bot_channels = int(round(num_channels * bot_mul))\n",
        "        self.conv1 = nn.LazyConv2d(bot_channels, kernel_size=1, stride=1)\n",
        "        self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3,\n",
        "                                   stride=strides, padding=1,\n",
        "                                   groups=bot_channels//groups)\n",
        "        self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=1)\n",
        "        self.bn1 = nn.LazyBatchNorm2d()\n",
        "        self.bn2 = nn.LazyBatchNorm2d()\n",
        "        self.bn3 = nn.LazyBatchNorm2d()\n",
        "        if use_1x1conv:\n",
        "            self.conv4 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                       stride=strides)\n",
        "            self.bn4 = nn.LazyBatchNorm2d()\n",
        "        else:\n",
        "            self.conv4 = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = F.relu(self.bn2(self.conv2(Y)))\n",
        "        Y = self.bn3(self.conv3(Y))\n",
        "        if self.conv4:\n",
        "            X = self.bn4(self.conv4(X))\n",
        "        return F.relu(Y + X)"
      ],
      "metadata": {
        "id": "b-dVTkhVCkrN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = ResNeXtBlock(32, 16, 1)\n",
        "X = torch.randn(4, 32, 96, 96)\n",
        "blk(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw8BXD8cDDuX",
        "outputId": "cf5e84a8-dffc-41f6-bcab-f0c0aa03f23c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 32, 96, 96])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNeXt(nn.Module):\n",
        "    def __init__(self, arch, num_classes=10, groups=32, bot_mul=2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(self.b1())\n",
        "        for i, b in enumerate(arch):\n",
        "            # Pass groups and bot_mul to the block method\n",
        "            self.net.add_module(f'b{i+2}', self.block(*b, groups=groups, bot_mul=bot_mul, first_block=(i==0)))\n",
        "        self.net.add_module('last', nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes)))\n",
        "\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def block(self, num_residuals, num_channels, groups, bot_mul, first_block=False):\n",
        "        blk = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                # Pass groups and bot_mul to ResNeXtBlock\n",
        "                blk.append(ResNeXtBlock(num_channels, groups, bot_mul, use_1x1conv=True, strides=2))\n",
        "            else:\n",
        "                # Pass groups and bot_mul to ResNeXtBlock\n",
        "                blk.append(ResNeXtBlock(num_channels, groups, bot_mul))\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.net(X)"
      ],
      "metadata": {
        "id": "BQBrXkS6DsnJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNext18(ResNeXt):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)),\n",
        "                       num_classes)"
      ],
      "metadata": {
        "id": "XbijLmanEesS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNext18()"
      ],
      "metadata": {
        "id": "ZnGnZxKgEnJf"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_PyTorch/blob/main/18VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils import data\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "Kt8X-b_z9rQd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The * before layers in return nn.Sequential(*layers) is the Python \"unpacking\" or \"splat\" operator. Here's what it does:\n",
        "\n",
        "layers is a list: In the vgg_block function, layers is built up as a Python list containing nn.LazyConv2d and nn.ReLU modules, followed by nn.MaxPool2d.\n",
        "nn.Sequential expects individual arguments: The nn.Sequential module in PyTorch expects its components as separate, individual arguments, not as a single list containing all components. For example, you would normally define it like nn.Sequential(layer1, layer2, layer3).\n",
        "*layers unpacks the list: When you use *layers, Python unpacks the elements of the layers list and passes each element as a separate argument to the nn.Sequential constructor. So, if layers contained [conv1, relu1, pool1], *layers would effectively become conv1, relu1, pool1 when passed to nn.Sequential."
      ],
      "metadata": {
        "id": "2id8dwMLDM5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR67ghT8LDAs",
        "outputId": "2d673130-67c7-474e-88b3-642c5b853f70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg_block(num_convs, out_channels):\n",
        "    layers = []\n",
        "    for _ in range(num_convs):\n",
        "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
        "        layers.append(nn.ReLU())\n",
        "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "wBdA2sCy9_Gr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        conv_blks = []\n",
        "        for (num_convs, out_channels) in arch:\n",
        "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
        "        self.net = nn.Sequential(\n",
        "            *conv_blks, nn.Flatten(),\n",
        "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.LazyLinear(num_classes))\n",
        "    def forward(self, X):\n",
        "      return self.net(X)"
      ],
      "metadata": {
        "id": "80BrANNd__h4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line (0): LazyConv2d(0, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) defines the first convolutional layer within a VGG block. Let me break it down:\n",
        "\n",
        "LazyConv2d: This is a PyTorch convolutional layer that automatically infers the in_channels (input channels) dimension when the model is first passed data. The 0 you see as the first argument indicates that the in_channels are not explicitly defined yet and will be determined dynamically.\n",
        "16: This is the out_channels argument, meaning this convolutional layer will produce 16 output channels.\n",
        "kernel_size=(3, 3): This specifies that the convolutional filter (kernel) has a size of 3x3 pixels.\n",
        "stride=(1, 1): This indicates that the kernel moves 1 pixel at a time horizontally and vertically across the input.\n",
        "padding=(1, 1): This adds a border of 1 pixel of zeros around the input image. For a 3x3 kernel and a stride of 1, padding of 1 typically helps to maintain the spatial dimensions of the output feature map the same as the input."
      ],
      "metadata": {
        "id": "-cxWE6FTBjmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)), lr=0.01)\n",
        "model.to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbVlIxkrAxT3",
        "outputId": "c6157581-94b2-4d9d-eef7-ad7665c6744e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): LazyConv2d(0, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (5): Flatten(start_dim=1, end_dim=-1)\n",
              "    (6): LazyLinear(in_features=0, out_features=4096, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): LazyLinear(in_features=0, out_features=4096, bias=True)\n",
              "    (10): ReLU()\n",
              "    (11): Dropout(p=0.5, inplace=False)\n",
              "    (12): LazyLinear(in_features=0, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10_dataset(batch_size=32):\n",
        "    # Define data transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize images to 224x224\n",
        "        transforms.ToTensor(),  # Convert images to tensors\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "    ])\n",
        "\n",
        "    # Load CIFAR-10 dataset\n",
        "    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "    test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "wFV5gpd_FOsC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = load_cifar10_dataset(batch_size=32)\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "giRDMJOZF-nP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        loss.backward()  # Backpropagate\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzKRB10hGLU_",
        "outputId": "34539768-3de6-42b2-d83f-576b751dab75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 2.3072\n",
            "Epoch [2/3], Loss: 1.5964\n",
            "Epoch [3/3], Loss: 1.3876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_accuracy_sum = 0\n",
        "test_n = 0\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    pred_outputs = torch.argmax(outputs, dim=1)\n",
        "    test_accuracy_sum += (pred_outputs == labels).float().sum()\n",
        "    test_n += labels.numel()\n",
        "  test_accuracy = test_accuracy_sum/test_n\n",
        "  print('test accuracy ', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBUyWFc4QtpX",
        "outputId": "464e7407-5655-4747-f126-7d18f8b76c68"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy  tensor(0.4788, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Fashion Mnist images"
      ],
      "metadata": {
        "id": "QXFTV0BIUi4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256"
      ],
      "metadata": {
        "id": "UrthA3HHU3Fn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ],
      "metadata": {
        "id": "tgej7U-SVAmw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = datasets.FashionMNIST(root=\"../data\", train=True, transform=Transform, download=True)\n",
        "mnist_val = datasets.FashionMNIST(root=\"../data\", train=False, transform=Transform, download=True)\n",
        "\n",
        "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=4)\n",
        "val_iter = data.DataLoader(mnist_val, batch_size, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZCcacu0UmRi",
        "outputId": "0a7cf5d2-413c-4fbc-e98f-015949b458ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelFashion = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)), lr=0.01)\n",
        "modelFashion.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqcTpd1TVerb",
        "outputId": "d5e32a2a-a8ad-4921-b930-ce242fb2918b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): LazyConv2d(0, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (5): Flatten(start_dim=1, end_dim=-1)\n",
              "    (6): LazyLinear(in_features=0, out_features=4096, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): LazyLinear(in_features=0, out_features=4096, bias=True)\n",
              "    (10): ReLU()\n",
              "    (11): Dropout(p=0.5, inplace=False)\n",
              "    (12): LazyLinear(in_features=0, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelFashion.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Esx6Xid4XwMZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_iter:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # Forward pass\n",
        "        outputs = modelFashion(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        loss.backward()  # Backpropagate\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdIs_QMvV7SI",
        "outputId": "9e99285d-00f2-4e89-fadf-ad8666f62572"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.2405\n",
            "Epoch [2/3], Loss: 0.4039\n",
            "Epoch [3/3], Loss: 0.2140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_accuracy_sum = 0\n",
        "test_n = 0\n",
        "with torch.no_grad():\n",
        "  for images, labels in val_iter:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = modelFashion(images)\n",
        "    pred_outputs = torch.argmax(outputs, dim=1)\n",
        "    test_accuracy_sum += (pred_outputs == labels).float().sum()\n",
        "    test_n += labels.numel()\n",
        "  test_accuracy = test_accuracy_sum/test_n\n",
        "  print('test accuracy ', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFp_kQDjZBdN",
        "outputId": "a316274c-256b-4c81-f1c2-1e1b3cc78ea8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy  tensor(0.9070, device='cuda:0')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_PyTorch/blob/main/23DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils import data\n",
        "from torchvision import datasets\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "AjpGZFLnbd9Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHdfRqslbtSo",
        "outputId": "f3dfc149-52d4-47b8-b8ce-e0ea4e4df8d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dense block"
      ],
      "metadata": {
        "id": "_BgGvMUaelHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.LazyConv2d(num_channels, kernel_size=3, padding=1))"
      ],
      "metadata": {
        "id": "VXZ8wzpJb0at"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_convs, num_channels):\n",
        "        super().__init__()\n",
        "        layer = []\n",
        "        for i in range(num_convs):\n",
        "            layer.append(conv_block(num_channels))\n",
        "        self.net = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for blk in self.net:\n",
        "            Y = blk(X)\n",
        "            # Concatenate input and output of each block along the channels\n",
        "            X = torch.cat((X, Y), dim=1)\n",
        "        return X"
      ],
      "metadata": {
        "id": "vAGgzRAYb5he"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of channels becomes 23 because of the way the DenseBlock concatenates the input and output of each conv_block. Let's trace the channel dimensions:\n",
        "\n",
        "Initial Input X: When you create X = torch.randn(4, 3, 8, 8), the input has 3 channels.\n",
        "First conv_block: The DenseBlock is initialized with num_convs=2 and num_channels=10. The first conv_block processes the initial X (3 channels) and outputs 10 channels (as defined by num_channels).\n",
        "First Concatenation: The forward method concatenates the original X (3 channels) with the output of the first conv_block (10 channels). So, 3 + 10 = 13 channels.\n",
        "Second conv_block: The second conv_block then receives this new X (13 channels) and outputs 10 channels.\n",
        "Second Concatenation: Finally, this X (13 channels) is concatenated with the output of the second conv_block (10 channels). So, 13 + 10 = 23 channels.\n",
        "This progressive concatenation leads to the final output having 23 channels."
      ],
      "metadata": {
        "id": "lSwqQ1M3ccQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------"
      ],
      "metadata": {
        "id": "t010qHkPeaZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Let's break down the concatenation process even further. The key operation here is torch.cat((X, Y), dim=1).\n",
        "\n",
        "torch.cat(): This PyTorch function is used to concatenate (join) tensors along a specified dimension.\n",
        "(X, Y): These are the two tensors being concatenated. X is the current accumulated input to the DenseBlock (or the initial input), and Y is the output of the latest conv_block.\n",
        "dim=1: This is crucial. In convolutional neural networks, the dimensions of a feature map are typically (batch_size, channels, height, width). When dim=1 is specified, torch.cat joins the tensors along the channel dimension. This means the number of channels from X and Y are added together.\n",
        "Let's re-trace with this in mind, assuming X starts with 3 channels and each conv_block outputs 10 channels (num_channels=10):\n",
        "\n",
        "Initial State: X has 3 channels. (e.g., (batch_size, 3, H, W))\n",
        "\n",
        "First conv_block execution:\n",
        "\n",
        "blk (the first conv_block) receives X (3 channels).\n",
        "Y = blk(X): Y will have 10 channels. (e.g., (batch_size, 10, H, W))\n",
        "First Concatenation:\n",
        "\n",
        "X = torch.cat((X, Y), dim=1):\n",
        "X (original) has 3 channels.\n",
        "Y (from conv_block) has 10 channels.\n",
        "The new X will have 3 + 10 = 13 channels. (e.g., (batch_size, 13, H, W))\n",
        "Second conv_block execution:\n",
        "\n",
        "blk (the second conv_block) receives the new X (which now has 13 channels).\n",
        "Y = blk(X): Y will still have 10 channels (because num_channels for conv_block is 10). (e.g., (batch_size, 10, H, W))\n",
        "Second Concatenation:\n",
        "\n",
        "X = torch.cat((X, Y), dim=1):\n",
        "X (current) has 13 channels.\n",
        "Y (from conv_block) has 10 channels.\n",
        "The final X will have 13 + 10 = 23 channels. (e.g., (batch_size, 23, H, W))\n",
        "So, each time a conv_block within the DenseBlock processes data, its output channels are appended to the existing input channels, causing the channel count to grow additively with each step."
      ],
      "metadata": {
        "id": "ecG9nmryeb53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blk = DenseBlock(2, 10)\n",
        "X = torch.randn(4, 3, 8, 8)\n",
        "Y = blk(X)\n",
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLC0IvR7b-3v",
        "outputId": "87678f20-9290-447e-bdd7-891499f4e7d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 23, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transition layer"
      ],
      "metadata": {
        "id": "CymPyF0SeqCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transition_block(num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.LazyConv2d(num_channels, kernel_size=1),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2))"
      ],
      "metadata": {
        "id": "FTbdJf1JesVK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape [4, 10, 4, 4] is obtained after blk(Y) due to the operations performed by the transition_block. Let's break it down:\n",
        "\n",
        "Input Y shape: From the previous execution, Y has a shape of [4, 23, 8, 8] (batch size 4, 23 channels, 8x8 spatial dimensions).\n",
        "\n",
        "nn.LazyBatchNorm2d() and nn.ReLU(): These layers are applied first within the transition_block. They perform normalization and activation functions, respectively, but do not change the spatial or channel dimensions of the tensor. So, the shape remains [4, 23, 8, 8].\n",
        "\n",
        "nn.LazyConv2d(num_channels, kernel_size=1): This is a 1x1 convolutional layer. You initialized the transition_block with num_channels=10 (i.e., transition_block(10)).\n",
        "\n",
        "A 1x1 convolution changes the number of output channels to num_channels (which is 10 here).\n",
        "It does not change the spatial dimensions (height and width) when kernel_size=1 and default padding/stride are used.\n",
        "So, after this layer, the tensor's shape becomes [4, 10, 8, 8].\n",
        "nn.AvgPool2d(kernel_size=2, stride=2): This is an average pooling layer with a kernel size of 2x2 and a stride of 2.\n",
        "\n",
        "Pooling layers reduce the spatial dimensions. With kernel_size=2 and stride=2, the height and width are effectively halved.\n",
        "The number of channels remains unchanged.\n",
        "So, after this layer, the spatial dimensions change from 8x8 to (8/2)x(8/2) = 4x4.\n",
        "The final shape becomes [4, 10, 4, 4].\n",
        "Combining these steps, the 1x1 convolution reduces the channels from 23 to 10, and the average pooling layer reduces the spatial dimensions from 8x8 to 4x4, resulting in the final shape [4, 10, 4, 4]."
      ],
      "metadata": {
        "id": "8vanbkYbfj0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blk = transition_block(10)\n",
        "blk(Y).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vvVMz-ee-AE",
        "outputId": "f84020a0-ef12-42b3-d974-6a713ceba692"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, num_channels=64, growth_rate=32, arch=(4, 4, 4, 4),\n",
        "                 num_classes=10):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(self.b1())\n",
        "        for i, num_convs in enumerate(arch):\n",
        "            self.net.add_module(f'dense_blk{i+1}', DenseBlock(num_convs,\n",
        "                                                              growth_rate))\n",
        "            # The number of output channels in the previous dense block\n",
        "            num_channels += num_convs * growth_rate\n",
        "            # A transition layer that halves the number of channels is added\n",
        "            # between the dense blocks\n",
        "            if i != len(arch) - 1:\n",
        "                num_channels //= 2\n",
        "                self.net.add_module(f'tran_blk{i+1}', transition_block(\n",
        "                    num_channels))\n",
        "        self.net.add_module('last', nn.Sequential(\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes)))\n",
        "\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "    def forward(self, X):\n",
        "        return self.net(X)"
      ],
      "metadata": {
        "id": "8Rlrk3Tcfq_x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DenseNet()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5h7V0vSgEG1",
        "outputId": "daafe1f6-8d7c-4d9b-8f9c-9f0d24a5235f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): LazyConv2d(0, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "      (1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (dense_blk1): DenseBlock(\n",
              "      (net): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (2): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (3): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (tran_blk1): Sequential(\n",
              "      (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (dense_blk2): DenseBlock(\n",
              "      (net): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (2): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (3): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (tran_blk2): Sequential(\n",
              "      (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 112, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (dense_blk3): DenseBlock(\n",
              "      (net): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (2): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (3): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (tran_blk3): Sequential(\n",
              "      (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (dense_blk4): DenseBlock(\n",
              "      (net): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (2): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (3): Sequential(\n",
              "          (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): ReLU()\n",
              "          (2): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (last): Sequential(\n",
              "      (0): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): ReLU()\n",
              "      (2): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (3): Flatten(start_dim=1, end_dim=-1)\n",
              "      (4): LazyLinear(in_features=0, out_features=10, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256"
      ],
      "metadata": {
        "id": "H1iCsvfzgQYw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ],
      "metadata": {
        "id": "J0a1QJregT0L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = datasets.FashionMNIST(root=\"../data\", train=True, transform=Transform, download=True)\n",
        "mnist_val = datasets.FashionMNIST(root=\"../data\", train=False, transform=Transform, download=True)\n",
        "\n",
        "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=2)\n",
        "val_iter = data.DataLoader(mnist_val, batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "qLotnSYUgXS7",
        "outputId": "c5058dd6-b82d-42c1-9960-85df53054291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 109MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 3.80MB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 60.3MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 34.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "3nzdf4TCgcLf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 3"
      ],
      "metadata": {
        "id": "E086Kr9mgfTB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(max_epochs):\n",
        "  model.train()\n",
        "  train_loss_sum, train_accuracy_sum, n = 0.0, 0.0, 0\n",
        "  for images, labels in train_iter:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    y_pred = model(images)\n",
        "    l = criterion(y_pred, labels)\n",
        "    optimizer.zero_grad()\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    train_loss_sum += l\n",
        "    predicted_labels = torch.argmax(y_pred, dim=1)\n",
        "    train_accuracy_sum += (predicted_labels == labels).float().sum()\n",
        "    n += labels.numel()\n",
        "\n",
        "  model.eval()\n",
        "  test_accuracy_sum, test_n = 0.0, 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in val_iter:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      y_pred = model(images)\n",
        "      predicted_labels = torch.argmax(y_pred, dim=1)\n",
        "      test_accuracy_sum += (predicted_labels == labels).float().sum()\n",
        "      test_n += labels.numel()\n",
        "  test_accuracy = test_accuracy_sum / test_n\n",
        "  print(f'Epoch {epoch + 1}, Loss: {train_loss_sum / n:.4f}, Train Accuracy: {train_accuracy_sum / n:.4f}, Validation Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "lK_keubgglx5",
        "outputId": "93020a4f-ba19-4ffe-fbc7-4046dc5f660c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.0022, Train Accuracy: 0.8059, Validation Accuracy: 0.7739\n",
            "Epoch 2, Loss: 0.0013, Train Accuracy: 0.8827, Validation Accuracy: 0.8632\n",
            "Epoch 3, Loss: 0.0010, Train Accuracy: 0.9028, Validation Accuracy: 0.8713\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
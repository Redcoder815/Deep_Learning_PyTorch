{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_PyTorch/blob/main/LinearNeuralNetworkForRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "gzRdY8Aj6-5U"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD():\n",
        "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
        "    def __init__(self, params, lr):\n",
        "        self.params = params\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self):\n",
        "        for param in self.params:\n",
        "            # Ensure param.grad is not None before performing operation\n",
        "            if param.grad is not None:\n",
        "                param.data -= self.lr * param.grad\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for param in self.params:\n",
        "            if param.grad is not None:\n",
        "                param.grad.zero_()"
      ],
      "metadata": {
        "id": "oaLOnWGDhGMd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e1cd391"
      },
      "source": [
        "class LinearRegressionScratch(nn.Module):\n",
        "    \"\"\"The linear regression model implemented from scratch.\"\"\"\n",
        "    def __init__(self, num_inputs, lr, sigma=0.01):\n",
        "        super().__init__()\n",
        "        self.lr = lr # Store lr as an instance attribute\n",
        "        self.w = torch.normal(0, sigma, (num_inputs, 1), requires_grad=True)\n",
        "        self.b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "      return torch.matmul(X, self.w) + self.b\n",
        "\n",
        "    def loss(self, y_hat, y):\n",
        "      l = (y_hat-y)**2 / 2\n",
        "      return l.mean()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      return SGD([self.w, self.b], self.lr)\n",
        "\n",
        "    def prepare_batch(self, batch):\n",
        "      return batch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62e49dd8"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "# 1. Define the true weight vector w and bias b\n",
        "true_w = torch.tensor([2, -3.4]).reshape(-1, 1)\n",
        "true_b = torch.tensor([4.2])\n",
        "\n",
        "# Define dataset parameters\n",
        "num_samples = 1000\n",
        "num_features = 2\n",
        "batch_size = 32\n",
        "\n",
        "# 2. Generate a synthetic dataset X of features and y of labels\n",
        "X = torch.randn(num_samples, num_features)\n",
        "y = torch.matmul(X, true_w) + true_b + torch.randn(num_samples, 1) * 0.01\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a798bc0"
      },
      "source": [
        "dataset = TensorDataset(X, y)\n",
        "\n",
        "# 4. Split the TensorDataset into training and validation sets\n",
        "train_size = int(0.8 * num_samples)\n",
        "val_size = num_samples - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# 5. Create DataLoader instances for both the training and validation sets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8567f678"
      },
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_dataloader, val_dataloader=None, max_epochs=10):\n",
        "        self.model = model\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.val_dataloader = val_dataloader\n",
        "        self.max_epochs = max_epochs\n",
        "        self.optim = model.configure_optimizers()\n",
        "\n",
        "    def fit(self):\n",
        "        for epoch in range(self.max_epochs):\n",
        "            self.model.train()\n",
        "            total_train_loss = 0\n",
        "            for X, y in self.train_dataloader:\n",
        "                # Forward pass\n",
        "                y_hat = self.model(X)\n",
        "                # Calculate loss\n",
        "                loss = self.model.loss(y_hat, y)\n",
        "\n",
        "                # Backpropagation\n",
        "                self.optim.zero_grad()\n",
        "                loss.backward()\n",
        "                # Optimization step\n",
        "                self.optim.step()\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = total_train_loss / len(self.train_dataloader)\n",
        "            print(f\"Epoch {epoch + 1}/{self.max_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "            # Validation loop (optional)\n",
        "            if self.val_dataloader is not None:\n",
        "                self.model.eval()\n",
        "                total_val_loss = 0\n",
        "                with torch.no_grad():\n",
        "                    for X_val, y_val in self.val_dataloader:\n",
        "                        y_hat_val = self.model(X_val)\n",
        "                        val_loss = self.model.loss(y_hat_val, y_val)\n",
        "                        total_val_loss += val_loss.item()\n",
        "                avg_val_loss = total_val_loss / len(self.val_dataloader)\n",
        "                print(f\"Epoch {epoch + 1}/{self.max_epochs}, Validation Loss: {avg_val_loss:.4f}\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba399052"
      },
      "source": [
        "model = LinearRegressionScratch(num_features, lr=0.03)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3742400b"
      },
      "source": [
        "max_epochs = 10\n",
        "trainer = Trainer(model, train_dataloader, val_dataloader, max_epochs=max_epochs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee9a0b02",
        "outputId": "297f061d-5b05-4f28-fb79-2e23cfae5d58"
      },
      "source": [
        "trainer.fit()\n",
        "print(\"Model training initiated.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 8.6922\n",
            "Epoch 1/10, Validation Loss: 4.4131\n",
            "Epoch 2/10, Training Loss: 1.9566\n",
            "Epoch 2/10, Validation Loss: 0.9995\n",
            "Epoch 3/10, Training Loss: 0.4413\n",
            "Epoch 3/10, Validation Loss: 0.2267\n",
            "Epoch 4/10, Training Loss: 0.0999\n",
            "Epoch 4/10, Validation Loss: 0.0515\n",
            "Epoch 5/10, Training Loss: 0.0227\n",
            "Epoch 5/10, Validation Loss: 0.0117\n",
            "Epoch 6/10, Training Loss: 0.0052\n",
            "Epoch 6/10, Validation Loss: 0.0026\n",
            "Epoch 7/10, Training Loss: 0.0012\n",
            "Epoch 7/10, Validation Loss: 0.0006\n",
            "Epoch 8/10, Training Loss: 0.0003\n",
            "Epoch 8/10, Validation Loss: 0.0002\n",
            "Epoch 9/10, Training Loss: 0.0001\n",
            "Epoch 9/10, Validation Loss: 0.0001\n",
            "Epoch 10/10, Training Loss: 0.0001\n",
            "Epoch 10/10, Validation Loss: 0.0000\n",
            "Model training initiated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With nn.Parameter()"
      ],
      "metadata": {
        "id": "EvwXrwg5gPCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "a1kCBLEBgTHQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionScratch(nn.Module):\n",
        "    \"\"\"The linear regression model implemented from scratch.\"\"\"\n",
        "    def __init__(self, num_inputs, lr, sigma=0.01):\n",
        "        super().__init__()\n",
        "        self.lr = lr # Store lr as an instance attribute\n",
        "        self.w = nn.Parameter(torch.normal(0, sigma, (num_inputs, 1))) # Wrapped in nn.Parameter\n",
        "        self.b = nn.Parameter(torch.zeros(1)) # Wrapped in nn.Parameter\n",
        "\n",
        "    def forward(self, X):\n",
        "      return torch.matmul(X, self.w) + self.b"
      ],
      "metadata": {
        "id": "n289vtdkgbHI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "# 1. Define the true weight vector w and bias b\n",
        "true_w = torch.tensor([2, -3.4]).reshape(-1, 1)\n",
        "true_b = torch.tensor([4.2])\n",
        "\n",
        "# Define dataset parameters\n",
        "num_samples = 1000\n",
        "num_features = 2\n",
        "batch_size = 32\n",
        "\n",
        "# 2. Generate a synthetic dataset X of features and y of labels\n",
        "X = torch.randn(num_samples, num_features)\n",
        "y = torch.matmul(X, true_w) + true_b + torch.randn(num_samples, 1) * 0.01"
      ],
      "metadata": {
        "id": "XzrcE8dVgilk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size,shuffle = True)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle = False)"
      ],
      "metadata": {
        "id": "sivcD1bEgmg6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegressionScratch(num_features, 0.001)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "OMD9d9fYgqX3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for inputs, targets in train_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "id": "-4NfJZ1ugtvL",
        "outputId": "3d644cb0-3963-4c08-8524-dcbbceab2d4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 34.2930\n",
            "Epoch [2/50], Loss: 33.8250\n",
            "Epoch [3/50], Loss: 33.3528\n",
            "Epoch [4/50], Loss: 32.8883\n",
            "Epoch [5/50], Loss: 32.4343\n",
            "Epoch [6/50], Loss: 31.9753\n",
            "Epoch [7/50], Loss: 31.5253\n",
            "Epoch [8/50], Loss: 31.0824\n",
            "Epoch [9/50], Loss: 30.6363\n",
            "Epoch [10/50], Loss: 30.2055\n",
            "Epoch [11/50], Loss: 29.7734\n",
            "Epoch [12/50], Loss: 29.3486\n",
            "Epoch [13/50], Loss: 28.9225\n",
            "Epoch [14/50], Loss: 28.5087\n",
            "Epoch [15/50], Loss: 28.0987\n",
            "Epoch [16/50], Loss: 27.6890\n",
            "Epoch [17/50], Loss: 27.2865\n",
            "Epoch [18/50], Loss: 26.8914\n",
            "Epoch [19/50], Loss: 26.4992\n",
            "Epoch [20/50], Loss: 26.1074\n",
            "Epoch [21/50], Loss: 25.7247\n",
            "Epoch [22/50], Loss: 25.3420\n",
            "Epoch [23/50], Loss: 24.9702\n",
            "Epoch [24/50], Loss: 24.5963\n",
            "Epoch [25/50], Loss: 24.2332\n",
            "Epoch [26/50], Loss: 23.8630\n",
            "Epoch [27/50], Loss: 23.5127\n",
            "Epoch [28/50], Loss: 23.1529\n",
            "Epoch [29/50], Loss: 22.8013\n",
            "Epoch [30/50], Loss: 22.4558\n",
            "Epoch [31/50], Loss: 22.1159\n",
            "Epoch [32/50], Loss: 21.7745\n",
            "Epoch [33/50], Loss: 21.4433\n",
            "Epoch [34/50], Loss: 21.1090\n",
            "Epoch [35/50], Loss: 20.7851\n",
            "Epoch [36/50], Loss: 20.4630\n",
            "Epoch [37/50], Loss: 20.1430\n",
            "Epoch [38/50], Loss: 19.8302\n",
            "Epoch [39/50], Loss: 19.5180\n",
            "Epoch [40/50], Loss: 19.2126\n",
            "Epoch [41/50], Loss: 18.9073\n",
            "Epoch [42/50], Loss: 18.6107\n",
            "Epoch [43/50], Loss: 18.3118\n",
            "Epoch [44/50], Loss: 18.0219\n",
            "Epoch [45/50], Loss: 17.7334\n",
            "Epoch [46/50], Loss: 17.4475\n",
            "Epoch [47/50], Loss: 17.1664\n",
            "Epoch [48/50], Loss: 16.8869\n",
            "Epoch [49/50], Loss: 16.6121\n",
            "Epoch [50/50], Loss: 16.3418\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_PyTorch/blob/main/15CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "13NcmWXjaALW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Cross-Correlation Operation"
      ],
      "metadata": {
        "id": "XlKAS8sejGLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d(X, K):\n",
        "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
        "    return Y"
      ],
      "metadata": {
        "id": "0dGQLgjsiwZ3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
        "corr2d(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOMqNmqti10B",
        "outputId": "3f258f72-738f-4092-bba9-dc350fd85c0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19., 25.],\n",
              "        [37., 43.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Layers"
      ],
      "metadata": {
        "id": "fSP3p20Ejlbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2D(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return corr2d(x, self.weight) + self.bias"
      ],
      "metadata": {
        "id": "pEuurS7yjncO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wSx0zZIkTbG",
        "outputId": "d80dfd81-f834-49ba-b935-1c0012e4da3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.tensor([[1.0, -1.0]])"
      ],
      "metadata": {
        "id": "n17NW3Fekx80"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = corr2d(X, K)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u61cXiDMlJgn",
        "outputId": "33861122-df70-46ac-a48b-66afcc50bda7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d(X.t(), K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLKap6U8lXsy",
        "outputId": "fe940e34-a5d9-4e47-ac17-1c296882ec1b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning a Kernel"
      ],
      "metadata": {
        "id": "qGi7OlKHlolM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a two-dimensional convolutional layer with 1 output channel and a\n",
        "# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=(1, 2), bias=False)\n",
        "\n",
        "# The two-dimensional convolutional layer uses four-dimensional input and\n",
        "# output in the format of (example, channel, height, width), where the batch\n",
        "# size (number of examples in the batch) and the number of channels are both 1\n",
        "X = X.reshape((1, 1, 6, 8))\n",
        "Y = Y.reshape((1, 1, 6, 7))\n",
        "lr = 3e-2  # Learning rate\n",
        "\n",
        "for i in range(10):\n",
        "    Y_hat = conv2d(X)\n",
        "    l = (Y_hat - Y) ** 2\n",
        "    conv2d.zero_grad()\n",
        "    l.sum().backward()\n",
        "    # Update the kernel\n",
        "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
        "    if (i + 1) % 2 == 0:\n",
        "        print(f'epoch {i + 1}, loss {l.sum():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4gHms_4vSJg",
        "outputId": "4c29a655-dc9d-4217-a3ed-f70add933fbf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, loss 16.628\n",
            "epoch 4, loss 5.101\n",
            "epoch 6, loss 1.802\n",
            "epoch 8, loss 0.690\n",
            "epoch 10, loss 0.275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d.weight.data.reshape((1, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBPwyYZRvjhb",
        "outputId": "074467c1-0d52-4877-f611-4e8af14f0045"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0397, -0.9326]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding"
      ],
      "metadata": {
        "id": "RnlxNohw5IY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define a helper function to calculate convolutions. It initializes the\n",
        "# convolutional layer weights and performs corresponding dimensionality\n",
        "# elevations and reductions on the input and output\n",
        "def comp_conv2d(conv2d, X):\n",
        "    # (1, 1) indicates that batch size and the number of channels are both 1\n",
        "    X = X.reshape((1, 1) + X.shape)\n",
        "    Y = conv2d(X)\n",
        "    # Strip the first two dimensions: examples and channels\n",
        "    return Y.reshape(Y.shape[2:])\n",
        "\n",
        "# 1 row and column is padded on either side, so a total of 2 rows or columns\n",
        "# are added\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n",
        "X = torch.rand(size=(8, 8))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb0Uck2D5J3m",
        "outputId": "cb123aef-a4e8-445e-ae13-381f74beba5f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use a convolution kernel with height 5 and width 3. The padding on either\n",
        "# side of the height and width are 2 and 1, respectively\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=(5, 3), padding=(2, 1))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnJ3x7B15_TH",
        "outputId": "1719d8fb-c434-467b-b4a0-7b36b145e99a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7af18a7"
      },
      "source": [
        "Let's break down how the output shape `(8, 8)` is obtained. The key factors are the input shape, kernel size, and padding. The formula to calculate the output dimensions for a convolutional layer (assuming a stride of 1, which is the default for `nn.Conv2d` when not specified) is:\n",
        "\n",
        "Output Height = `(Input Height - Kernel Height + 2 * Padding Height) + 1`\n",
        "Output Width = `(Input Width - Kernel Width + 2 * Padding Width) + 1`\n",
        "\n",
        "In the code block, you have:\n",
        "*   **Input shape (X):** `(8, 8)` (so, `Input Height = 8`, `Input Width = 8`)\n",
        "*   **Kernel size:** `(5, 3)` (so, `Kernel Height = 5`, `Kernel Width = 3`)\n",
        "*   **Padding:** `(2, 1)` (so, `Padding Height = 2`, `Padding Width = 1`)\n",
        "\n",
        "Now, let's plug these values into the formulas:\n",
        "\n",
        "**For the Output Height:**\n",
        "`Output Height = (8 - 5 + 2 * 2) + 1`\n",
        "`Output Height = (8 - 5 + 4) + 1`\n",
        "`Output Height = (3 + 4) + 1`\n",
        "`Output Height = 7 + 1 = 8`\n",
        "\n",
        "**For the Output Width:**\n",
        "`Output Width = (8 - 3 + 2 * 1) + 1`\n",
        "`Output Width = (8 - 3 + 2) + 1`\n",
        "`Output Width = (5 + 2) + 1`\n",
        "`Output Width = 7 + 1 = 8`\n",
        "\n",
        "Therefore, the resulting output shape is `(8, 8)`, which matches the output `torch.Size([8, 8])` you observed. The padding effectively compensates for the reduction in size caused by the kernel, allowing the output to maintain the same dimensions as the input."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stride"
      ],
      "metadata": {
        "id": "sswHp-S3AIid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmfPJIi2AHIY",
        "outputId": "ef4c7f3b-ff6f-44df-c98a-d48f53f219ea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsXoHkBjANzi",
        "outputId": "e3bfa820-91d4-4f4b-b0c9-3163c0b0f156"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d124a351"
      },
      "source": [
        "Let's break down how the output shape `(2, 2)` is obtained for the last code block. This time, in addition to input shape, kernel size, and padding, the **stride** plays a crucial role. The general formulas to calculate the output dimensions for a convolutional layer are:\n",
        "\n",
        "Output Height = `floor((Input Height - Kernel Height + 2 * Padding Height) / Stride Height) + 1`\n",
        "Output Width = `floor((Input Width - Kernel Width + 2 * Padding Width) / Stride Width) + 1`\n",
        "\n",
        "In the code block, you have:\n",
        "*   **Input shape (X):** `(8, 8)` (so, `Input Height = 8`, `Input Width = 8`)\n",
        "*   **Kernel size:** `(3, 5)` (so, `Kernel Height = 3`, `Kernel Width = 5`)\n",
        "*   **Padding:** `(0, 1)` (so, `Padding Height = 0`, `Padding Width = 1`)\n",
        "*   **Stride:** `(3, 4)` (so, `Stride Height = 3`, `Stride Width = 4`)\n",
        "\n",
        "Now, let's plug these values into the formulas:\n",
        "\n",
        "**For the Output Height:**\n",
        "`Output Height = floor((8 - 3 + 2 * 0) / 3) + 1`\n",
        "`Output Height = floor((5 + 0) / 3) + 1`\n",
        "`Output Height = floor(5 / 3) + 1`\n",
        "`Output Height = floor(1.666...) + 1`\n",
        "`Output Height = 1 + 1 = 2`\n",
        "\n",
        "**For the Output Width:**\n",
        "`Output Width = floor((8 - 5 + 2 * 1) / 4) + 1`\n",
        "`Output Width = floor((3 + 2) / 4) + 1`\n",
        "`Output Width = floor(5 / 4) + 1`\n",
        "`Output Width = floor(1.25) + 1`\n",
        "`Output Width = 1 + 1 = 2`\n",
        "\n",
        "Therefore, the resulting output shape is `(2, 2)`, which matches the output `torch.Size([2, 2])` you observed. The stride significantly reduces the output dimensions by controlling how many pixels the kernel skips during its movement across the input."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
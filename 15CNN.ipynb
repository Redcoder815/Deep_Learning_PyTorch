{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_PyTorch/blob/main/15CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "13NcmWXjaALW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Cross-Correlation Operation"
      ],
      "metadata": {
        "id": "XlKAS8sejGLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d(X, K):\n",
        "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
        "    return Y"
      ],
      "metadata": {
        "id": "0dGQLgjsiwZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
        "corr2d(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOMqNmqti10B",
        "outputId": "5b0a8fc6-24c6-4ef1-9b02-cb6adb8f2b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19., 25.],\n",
              "        [37., 43.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Layers"
      ],
      "metadata": {
        "id": "fSP3p20Ejlbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2D(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return corr2d(x, self.weight) + self.bias"
      ],
      "metadata": {
        "id": "pEuurS7yjncO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wSx0zZIkTbG",
        "outputId": "a568a663-bd0c-4d13-ad4a-afece913de91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.tensor([[1.0, -1.0]])"
      ],
      "metadata": {
        "id": "n17NW3Fekx80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = corr2d(X, K)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u61cXiDMlJgn",
        "outputId": "63c06a15-36af-4a3c-8fc6-5702d9158756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d(X.t(), K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLKap6U8lXsy",
        "outputId": "f100ec4b-95e6-4201-d58a-4179754ca389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning a Kernel"
      ],
      "metadata": {
        "id": "qGi7OlKHlolM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a two-dimensional convolutional layer with 1 output channel and a\n",
        "# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=(1, 2), bias=False)\n",
        "\n",
        "# The two-dimensional convolutional layer uses four-dimensional input and\n",
        "# output in the format of (example, channel, height, width), where the batch\n",
        "# size (number of examples in the batch) and the number of channels are both 1\n",
        "X = X.reshape((1, 1, 6, 8))\n",
        "Y = Y.reshape((1, 1, 6, 7))\n",
        "lr = 3e-2  # Learning rate\n",
        "\n",
        "for i in range(10):\n",
        "    Y_hat = conv2d(X)\n",
        "    l = (Y_hat - Y) ** 2\n",
        "    conv2d.zero_grad()\n",
        "    l.sum().backward()\n",
        "    # Update the kernel\n",
        "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
        "    if (i + 1) % 2 == 0:\n",
        "        print(f'epoch {i + 1}, loss {l.sum():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4gHms_4vSJg",
        "outputId": "9b80dcbd-2106-42e6-aee8-ed88293d2d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, loss 12.942\n",
            "epoch 4, loss 2.189\n",
            "epoch 6, loss 0.374\n",
            "epoch 8, loss 0.066\n",
            "epoch 10, loss 0.012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d.weight.data.reshape((1, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBPwyYZRvjhb",
        "outputId": "2195b682-bc3f-4ffb-cbe2-26bc378660d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9767, -0.9860]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding"
      ],
      "metadata": {
        "id": "RnlxNohw5IY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define a helper function to calculate convolutions. It initializes the\n",
        "# convolutional layer weights and performs corresponding dimensionality\n",
        "# elevations and reductions on the input and output\n",
        "def comp_conv2d(conv2d, X):\n",
        "    # (1, 1) indicates that batch size and the number of channels are both 1\n",
        "    X = X.reshape((1, 1) + X.shape)\n",
        "    Y = conv2d(X)\n",
        "    # Strip the first two dimensions: examples and channels\n",
        "    return Y.reshape(Y.shape[2:])\n",
        "\n",
        "# 1 row and column is padded on either side, so a total of 2 rows or columns\n",
        "# are added\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n",
        "X = torch.rand(size=(8, 8))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb0Uck2D5J3m",
        "outputId": "21b09245-d720-4514-e1cb-dc2b5491b38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use a convolution kernel with height 5 and width 3. The padding on either\n",
        "# side of the height and width are 2 and 1, respectively\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=(5, 3), padding=(2, 1))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnJ3x7B15_TH",
        "outputId": "727376ef-5fd7-4d9c-9d45-729ce45d7924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7af18a7"
      },
      "source": [
        "Let's break down how the output shape `(8, 8)` is obtained. The key factors are the input shape, kernel size, and padding. The formula to calculate the output dimensions for a convolutional layer (assuming a stride of 1, which is the default for `nn.Conv2d` when not specified) is:\n",
        "\n",
        "Output Height = `(Input Height - Kernel Height + 2 * Padding Height) + 1`\n",
        "Output Width = `(Input Width - Kernel Width + 2 * Padding Width) + 1`\n",
        "\n",
        "In the code block, you have:\n",
        "*   **Input shape (X):** `(8, 8)` (so, `Input Height = 8`, `Input Width = 8`)\n",
        "*   **Kernel size:** `(5, 3)` (so, `Kernel Height = 5`, `Kernel Width = 3`)\n",
        "*   **Padding:** `(2, 1)` (so, `Padding Height = 2`, `Padding Width = 1`)\n",
        "\n",
        "Now, let's plug these values into the formulas:\n",
        "\n",
        "**For the Output Height:**\n",
        "`Output Height = (8 - 5 + 2 * 2) + 1`\n",
        "`Output Height = (8 - 5 + 4) + 1`\n",
        "`Output Height = (3 + 4) + 1`\n",
        "`Output Height = 7 + 1 = 8`\n",
        "\n",
        "**For the Output Width:**\n",
        "`Output Width = (8 - 3 + 2 * 1) + 1`\n",
        "`Output Width = (8 - 3 + 2) + 1`\n",
        "`Output Width = (5 + 2) + 1`\n",
        "`Output Width = 7 + 1 = 8`\n",
        "\n",
        "Therefore, the resulting output shape is `(8, 8)`, which matches the output `torch.Size([8, 8])` you observed. The padding effectively compensates for the reduction in size caused by the kernel, allowing the output to maintain the same dimensions as the input."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stride"
      ],
      "metadata": {
        "id": "sswHp-S3AIid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmfPJIi2AHIY",
        "outputId": "a07713b0-0286-4ce5-c76a-68bf53bea7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsXoHkBjANzi",
        "outputId": "cbf2e6b5-693b-4418-e3c5-b1c43a813c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Input Channels"
      ],
      "metadata": {
        "id": "2jVGiUc7OFJn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d124a351"
      },
      "source": [
        "Let's break down how the output shape `(2, 2)` is obtained for the last code block. This time, in addition to input shape, kernel size, and padding, the **stride** plays a crucial role. The general formulas to calculate the output dimensions for a convolutional layer are:\n",
        "\n",
        "Output Height = `floor((Input Height - Kernel Height + 2 * Padding Height) / Stride Height) + 1`\n",
        "Output Width = `floor((Input Width - Kernel Width + 2 * Padding Width) / Stride Width) + 1`\n",
        "\n",
        "In the code block, you have:\n",
        "*   **Input shape (X):** `(8, 8)` (so, `Input Height = 8`, `Input Width = 8`)\n",
        "*   **Kernel size:** `(3, 5)` (so, `Kernel Height = 3`, `Kernel Width = 5`)\n",
        "*   **Padding:** `(0, 1)` (so, `Padding Height = 0`, `Padding Width = 1`)\n",
        "*   **Stride:** `(3, 4)` (so, `Stride Height = 3`, `Stride Width = 4`)\n",
        "\n",
        "Now, let's plug these values into the formulas:\n",
        "\n",
        "**For the Output Height:**\n",
        "`Output Height = floor((8 - 3 + 2 * 0) / 3) + 1`\n",
        "`Output Height = floor((5 + 0) / 3) + 1`\n",
        "`Output Height = floor(5 / 3) + 1`\n",
        "`Output Height = floor(1.666...) + 1`\n",
        "`Output Height = 1 + 1 = 2`\n",
        "\n",
        "**For the Output Width:**\n",
        "`Output Width = floor((8 - 5 + 2 * 1) / 4) + 1`\n",
        "`Output Width = floor((3 + 2) / 4) + 1`\n",
        "`Output Width = floor(5 / 4) + 1`\n",
        "`Output Width = floor(1.25) + 1`\n",
        "`Output Width = 1 + 1 = 2`\n",
        "\n",
        "Therefore, the resulting output shape is `(2, 2)`, which matches the output `torch.Size([2, 2])` you observed. The stride significantly reduces the output dimensions by controlling how many pixels the kernel skips during its movement across the input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd318d47"
      },
      "source": [
        "The last code block you executed demonstrates how the `corr2d_multi_in` function works with a concrete example:\n",
        "\n",
        "1.  **`X_multi_in` (Input with 2 Channels):**\n",
        "    *   It defines a `torch.Tensor` named `X_multi_in` with a shape of `(2, 3, 3)`. This represents an input with 2 channels, where each channel is a `3x3` matrix. Think of it like a simplified 2-channel image where each channel holds different feature information.\n",
        "    *   `Channel 1`: `[[0., 1., 2.], [3., 4., 5.], [6., 7., 8.]]`\n",
        "    *   `Channel 2`: `[[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]`\n",
        "\n",
        "2.  **`K_multi_in` (Kernel with 2 Input Channels):**\n",
        "    *   It defines a `torch.Tensor` named `K_multi_in` with a shape of `(2, 2, 2)`. This is a convolution kernel designed to operate on inputs with 2 channels, where each channel has a `2x2` kernel.\n",
        "    *   `Kernel for Channel 1`: `[[0., 1.], [2., 3.]]`\n",
        "    *   `Kernel for Channel 2`: `[[1., 0.], [3., 2.]]`\n",
        "\n",
        "3.  **`Y_multi_in = corr2d_multi_in(X_multi_in, K_multi_in)`:**\n",
        "    *   This line calls the `corr2d_multi_in` function with the multi-channel input `X_multi_in` and multi-channel kernel `K_multi_in`.\n",
        "    *   Internally, `corr2d_multi_in` does the following:\n",
        "        *   It performs `corr2d(X_multi_in[0], K_multi_in[0])` (cross-correlation for the first channel).\n",
        "        *   It performs `corr2d(X_multi_in[1], K_multi_in[1])` (cross-correlation for the second channel).\n",
        "        *   It then **sums** the results of these two individual cross-correlations element-wise to produce a single output feature map.\n",
        "\n",
        "4.  **Output Calculation Breakdown (as the function does it):\n",
        "    *   For Channel 1 (`X_multi_in[0]` and `K_multi_in[0]`):\n",
        "        `corr2d(torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]), torch.tensor([[0.0, 1.0], [2.0, 3.0]]))`\n",
        "        This would yield `torch.tensor([[19., 25.], [37., 43.]])` (as seen in earlier examples).\n",
        "\n",
        "    *   For Channel 2 (`X_multi_in[1]` and `K_multi_in[1]`):\n",
        "        `corr2d(torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]), torch.tensor([[1.0, 0.0], [3.0, 2.0]]))`\n",
        "        Let's calculate this manually:\n",
        "        *   Top-left: `(1*1 + 2*0 + 4*3 + 5*2) = 1 + 0 + 12 + 10 = 23`\n",
        "        *   Top-right: `(2*1 + 3*0 + 5*3 + 6*2) = 2 + 0 + 15 + 12 = 29`\n",
        "        *   Bottom-left: `(4*1 + 5*0 + 7*3 + 8*2) = 4 + 0 + 21 + 16 = 41`\n",
        "        *   Bottom-right: `(5*1 + 6*0 + 8*3 + 9*2) = 5 + 0 + 24 + 18 = 47`\n",
        "        So, `torch.tensor([[23., 29.], [41., 47.]])`\n",
        "\n",
        "    *   **Summing the results:**\n",
        "        `[[19., 25.], [37., 43.]] + [[23., 29.], [41., 47.]] = [[19+23, 25+29], [37+41, 43+47]] = [[42., 54.], [78., 90.]]`\n",
        "\n",
        "    The output `Y_multi_in` will therefore be `torch.tensor([[42., 54.], [78., 90.]])`, representing the aggregated feature map across all input channels."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in(X, K):\n",
        "    # Iterate through the 0th dimension (channel) of K first, then add them up\n",
        "    return sum(corr2d(x, k) for x, k in zip(X, K))"
      ],
      "metadata": {
        "id": "84h2RQeML3ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f16f5e08"
      },
      "source": [
        "Let's explain the result of the last executed code block with `X` and `K` from that block:\n",
        "\n",
        "**Input `X`:**\n",
        "```\n",
        "torch.tensor([[[\n",
        "    [0.0, 1.0, 2.0],\n",
        "    [3.0, 4.0, 5.0],\n",
        "    [6.0, 7.0, 8.0]]],  # Channel 1\n",
        "\n",
        "   [[\n",
        "    [1.0, 2.0, 3.0],\n",
        "    [4.0, 5.0, 6.0],\n",
        "    [7.0, 8.0, 9.0]]]]) # Channel 2\n",
        "```\n",
        "\n",
        "**Kernel `K`:**\n",
        "```\n",
        "torch.tensor([[[\n",
        "    [0.0, 1.0],\n",
        "    [2.0, 3.0]]],  # Kernel for Channel 1\n",
        "\n",
        "   [[\n",
        "    [1.0, 2.0],\n",
        "    [3.0, 4.0]]]]) # Kernel for Channel 2\n",
        "```\n",
        "\n",
        "The `corr2d_multi_in(X, K)` function performs two individual `corr2d` operations (one for each channel) and then sums their outputs.\n",
        "\n",
        "### **Step 1: Cross-correlation for Channel 1**\n",
        "\n",
        "`X_ch1 = [[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]`\n",
        "`K_ch1 = [[0.0, 1.0], [2.0, 3.0]]`\n",
        "\n",
        "Applying `corr2d(X_ch1, K_ch1)` (as we've seen in previous examples):\n",
        "\n",
        "*   **Element (0,0):** `(0*0 + 1*1 + 3*2 + 4*3) = 0 + 1 + 6 + 12 = 19`\n",
        "*   **Element (0,1):** `(1*0 + 2*1 + 4*2 + 5*3) = 0 + 2 + 8 + 15 = 25`\n",
        "*   **Element (1,0):** `(3*0 + 4*1 + 6*2 + 7*3) = 0 + 4 + 12 + 21 = 37`\n",
        "*   **Element (1,1):** `(4*0 + 5*1 + 7*2 + 8*3) = 0 + 5 + 14 + 24 = 43`\n",
        "\n",
        "**Result for Channel 1:**\n",
        "```\n",
        "torch.tensor([[\n",
        "    [19., 25.],\n",
        "    [37., 43.]]])\n",
        "```\n",
        "\n",
        "### **Step 2: Cross-correlation for Channel 2**\n",
        "\n",
        "`X_ch2 = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]`\n",
        "`K_ch2 = [[1.0, 2.0], [3.0, 4.0]]`\n",
        "\n",
        "Applying `corr2d(X_ch2, K_ch2)`:\n",
        "\n",
        "*   **Element (0,0):** `(1*1 + 2*2 + 4*3 + 5*4) = 1 + 4 + 12 + 20 = 37`\n",
        "*   **Element (0,1):** `(2*1 + 3*2 + 5*3 + 6*4) = 2 + 6 + 15 + 24 = 47`\n",
        "*   **Element (1,0):** `(4*1 + 5*2 + 7*3 + 8*4) = 4 + 10 + 21 + 32 = 67`\n",
        "*   **Element (1,1):** `(5*1 + 6*2 + 8*3 + 9*4) = 5 + 12 + 24 + 36 = 77`\n",
        "\n",
        "**Result for Channel 2:**\n",
        "```\n",
        "torch.tensor([[\n",
        "    [37., 47.],\n",
        "    [67., 77.]]])\n",
        "```\n",
        "\n",
        "### **Step 3: Summing the Results of All Channels**\n",
        "\n",
        "Finally, `corr2d_multi_in` sums the results from each channel element-wise:\n",
        "\n",
        "```\n",
        "[[19., 25.],   +   [[37., 47.],   =   [[19+37, 25+47],\n",
        " [37., 43.]]       [67., 77.]]       [37+67, 43+77]]\n",
        "\n",
        "= [[56.,  72.],\n",
        "   [104., 120.]]\n",
        "```\n",
        "\n",
        "This matches the output you observed: `tensor([[ 56.,  72.], [104., 120.]])`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
        "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
        "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
        "\n",
        "corr2d_multi_in(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKi6uuopMyzR",
        "outputId": "2e010ef1-2924-4ce4-e3a4-75a0dc8c81ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  72.],\n",
              "        [104., 120.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Output Channels"
      ],
      "metadata": {
        "id": "ZdDHTse_ONZP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1f06aac"
      },
      "source": [
        "Let's re-explain how the `corr2d_multi_in_out(X, K)` function works, focusing on the input and kernel shapes and what happens at each step:\n",
        "\n",
        "**Function Definition:**\n",
        "```python\n",
        "def corr2d_multi_in_out(X, K):\n",
        "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)\n",
        "```\n",
        "\n",
        "**Assumptions about `X` and `K`:**\n",
        "\n",
        "*   **Input `X`:** This is your input feature map(s). It has multiple input channels.\n",
        "    *   Its shape is `(num_input_channels, height, width)`.\n",
        "    *   For our example, `X` has shape `(2, 3, 3)`.\n",
        "\n",
        "*   **Kernel `K` (for `corr2d_multi_in_out`):** This kernel is designed to produce multiple output channels.\n",
        "    *   Its shape is `(num_output_channels, num_input_channels, kernel_height, kernel_width)`.\n",
        "    *   For our example, after `K = torch.stack((K, K + 1, K + 2), 0)`, this `K` has shape `(3, 2, 2, 2)`.\n",
        "\n",
        "**Step-by-Step Breakdown:**\n",
        "\n",
        "1.  **`for k in K`:** The core of this function is a list comprehension `[corr2d_multi_in(X, k) for k in K]`. This loop iterates through the *first dimension* of the kernel `K`.\n",
        "\n",
        "    *   In our example, `K` has `num_output_channels = 3` along its first dimension. So, the loop will run 3 times.\n",
        "\n",
        "    *   **Iteration 1:** `k` becomes `K[0]`.\n",
        "        *   `K[0]` is a 3D tensor with shape `(num_input_channels, kernel_height, kernel_width)`, which is `(2, 2, 2)` in our case.\n",
        "        *   This `K[0]` represents the set of kernels that will produce the *first output channel*.\n",
        "\n",
        "    *   **Iteration 2:** `k` becomes `K[1]`.\n",
        "        *   `K[1]` also has shape `(2, 2, 2)`.\n",
        "        *   This `K[1]` represents the set of kernels that will produce the *second output channel*.\n",
        "\n",
        "    *   **Iteration 3:** `k` becomes `K[2]`.\n",
        "        *   `K[2]` also has shape `(2, 2, 2)`.\n",
        "        *   This `K[2]` represents the set of kernels that will produce the *third output channel*.\n",
        "\n",
        "2.  **`corr2d_multi_in(X, k)` (inside the loop):** In each iteration, `corr2d_multi_in` is called with the original multi-channel input `X` and the current `k` (which is a kernel set for *one* output channel).\n",
        "\n",
        "    *   Recall that `corr2d_multi_in(X, k)` does the following:\n",
        "        *   It takes `X` (e.g., `(2, 3, 3)`) and `k` (e.g., `(2, 2, 2)`).\n",
        "        *   It performs `corr2d(X[0], k[0])` (cross-correlation for input channel 0).\n",
        "        *   It performs `corr2d(X[1], k[1])` (cross-correlation for input channel 1).\n",
        "        *   It then **sums these results** element-wise.\n",
        "    *   The output of `corr2d_multi_in(X, k)` is a single 2D tensor (e.g., `(2, 2)`), representing *one* output feature map (one output channel).\n",
        "\n",
        "    *   So, in our example:\n",
        "        *   `corr2d_multi_in(X, K[0])` produces the **first output feature map** (shape `(2, 2)`).\n",
        "        *   `corr2d_multi_in(X, K[1])` produces the **second output feature map** (shape `(2, 2)`).\n",
        "        *   `corr2d_multi_in(X, K[2])` produces the **third output feature map** (shape `(2, 2)`).\n",
        "\n",
        "3.  **`torch.stack([...], 0)` (after the loop):** The list comprehension generates a list containing these three 2D output feature maps.\n",
        "\n",
        "    *   `torch.stack` then takes this list of 2D tensors `[output_map_0, output_map_1, output_map_2]` and stacks them along a new dimension at index `0`.\n",
        "\n",
        "    *   This combines them into a single 3D tensor where the new first dimension corresponds to the `num_output_channels`.\n",
        "\n",
        "    *   The final output shape will be `(num_output_channels, output_height, output_width)`.\n",
        "    *   In our example, the final output shape is `(3, 2, 2)`.\n",
        "\n",
        "**In summary:** `corr2d_multi_in_out` processes the input `X` with *each complete set of kernels* (each `k` from the first dimension of the main `K`) independently. Each of these independent processing steps, handled by `corr2d_multi_in`, generates one output channel. Finally, all these generated output channels are stacked together to form the multi-channel output."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in_out(X, K):\n",
        "    # Iterate through the 0th dimension of K, and each time, perform\n",
        "    # cross-correlation operations with input X. All of the results are\n",
        "    # stacked together\n",
        "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
      ],
      "metadata": {
        "id": "gXMZ5HoKT5bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eaf9b92"
      },
      "source": [
        "Let's re-explain the line `K = torch.stack((K, K + 1, K + 2), 0)`.\n",
        "\n",
        "Imagine you have a single `K` which is like a recipe for a certain flavor (output feature).\n",
        "\n",
        "Initially, `K` has a shape like `(num_input_channels, kernel_height, kernel_width)`. Let's say, in our example, `K.shape` was `(2, 2, 2)`.\n",
        "\n",
        "This means:\n",
        "*   It takes `2` input channels.\n",
        "*   For each input channel, it has a `2x2` kernel.\n",
        "\n",
        "Now, let's look at `torch.stack((K, K + 1, K + 2), 0)`:\n",
        "\n",
        "1.  **`K`**: This is your original recipe (kernel set).\n",
        "\n",
        "2.  **`K + 1`**: This creates a *new* recipe. It's similar to the original `K`, but every number in it has been increased by 1. So, it will produce a *different* flavor or detect *different* features.\n",
        "\n",
        "3.  **`K + 2`**: This creates *another* new recipe, where every number from the original `K` has been increased by 2. This is yet another unique recipe/flavor.\n",
        "\n",
        "4.  **`torch.stack( (recipe1, recipe2, recipe3), dim=0)`**: The `torch.stack` function takes these individual recipes (tensors) and bundles them together into a *new* dimension. The `dim=0` means it puts them one on top of the other, creating a new \"outermost\" dimension.\n",
        "\n",
        "**Visualizing the dimensions:**\n",
        "\n",
        "*   Original `K` shape: `(2, 2, 2)` (e.g., `[InputChannel, Height, Width]`). This can be thought of as a single \"output kernel set\" that produces one output feature map.\n",
        "\n",
        "*   When you do `torch.stack((K, K + 1, K + 2), 0)`, you are essentially saying:\n",
        "    *   \"Here's my first set of kernels (`K`) to produce **Output Channel 1**.\"\n",
        "    *   \"Here's my second set of kernels (`K + 1`) to produce **Output Channel 2**.\"\n",
        "    *   \"Here's my third set of kernels (`K + 2`) to produce **Output Channel 3**.\"\n",
        "\n",
        "    And you stack these three sets along a new 0-th dimension.\n",
        "\n",
        "*   The new `K` will have a shape like: `(3, 2, 2, 2)`.\n",
        "    *   The `3` at the beginning signifies that this new `K` is now a collection of 3 *different* kernel sets, each designed to produce a separate *output channel*.\n",
        "    *   The `2, 2, 2` that follows for each of the 3 sets is still `[InputChannel, Height, Width]` for that particular output channel's kernel set.\n",
        "\n",
        "So, this operation effectively transforms a kernel designed for a single output channel (given multiple input channels) into a kernel designed to produce *multiple* output channels (still considering multiple input channels for each output). Each of the 3 \"stacked\" `K`s will be used by `corr2d_multi_in_out` to generate one of the three output feature maps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "763c4b9b"
      },
      "source": [
        "The line `K = torch.stack((K, K + 1, K + 2), 0)` is designed to create a new multi-dimensional kernel that can produce multiple output channels.\n",
        "\n",
        "Let's break it down:\n",
        "\n",
        "1.  **Original `K`:** Before this line, `K` was a tensor representing a kernel structure with multiple *input* channels. Its shape was `(num_input_channels, kernel_height, kernel_width)`.\n",
        "    *   For example, in the previous code block, `K` was `torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])`, which has a shape of `(2, 2, 2)`. This means it had 2 input channels, each with a 2x2 kernel.\n",
        "\n",
        "2.  **`K + 1` and `K + 2`:** These operations perform element-wise addition to the original `K` tensor. They create new kernel tensors that are essentially shifted versions of the original `K`.\n",
        "    *   `K + 1` results in a new kernel tensor where every element of the original `K` has been increased by 1.\n",
        "    *   `K + 2` results in a new kernel tensor where every element of the original `K` has been increased by 2.\n",
        "\n",
        "3.  **`torch.stack((K, K + 1, K + 2), 0)`:** The `torch.stack` function takes a sequence of tensors and concatenates them along a *new* dimension. The `0` indicates that this new dimension should be inserted at the very beginning (index 0) of the tensor's shape.\n",
        "    *   You are stacking three tensors: the original `K`, `K + 1`, and `K + 2`.\n",
        "    *   Each of these three tensors has the shape of the original `K` (e.g., `(2, 2, 2)`).\n",
        "    *   By stacking them along dimension 0, you are essentially creating 3 *output* channels. Each of these output channels will be generated by its own distinct set of kernels (the original `K`, `K+1`, or `K+2`).\n",
        "\n",
        "**Resulting `K` Shape:**\n",
        "\n",
        "If the original `K` had a shape of `(C_in, H_k, W_k)` (e.g., `(2, 2, 2)`), after this `stack` operation, the new `K` will have a shape of `(3, C_in, H_k, W_k)` (e.g., `(3, 2, 2, 2)`).\n",
        "\n",
        "*   The first dimension (`3`) now represents the number of *output* channels.\n",
        "*   The second dimension (`C_in`) represents the number of *input* channels that each output kernel operates on.\n",
        "*   The remaining dimensions (`H_k`, `W_k`) are the height and width of each individual kernel within the output channel.\n",
        "\n",
        "This new `K` is then used by `corr2d_multi_in_out` to produce three separate output feature maps, each corresponding to one of the stacked kernel sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = torch.stack((K, K + 1, K + 2), 0)\n",
        "K.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXH3LtEkQwUF",
        "outputId": "f57bbe4b-f714-4c6d-d782-263fe3e9cc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d_multi_in_out(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpbK6U9uPKkc",
        "outputId": "e46b9094-af72-403a-e089-91451154ba4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 56.,  72.],\n",
              "         [104., 120.]],\n",
              "\n",
              "        [[ 76., 100.],\n",
              "         [148., 172.]],\n",
              "\n",
              "        [[ 96., 128.],\n",
              "         [192., 224.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1x1 Convolutional Layer"
      ],
      "metadata": {
        "id": "JZnYfxbFWKbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in_out_1x1(X, K):\n",
        "    c_i, h, w = X.shape\n",
        "    c_o = K.shape[0]\n",
        "    X = X.reshape((c_i, h * w))\n",
        "    K = K.reshape((c_o, c_i))\n",
        "    # Matrix multiplication in the fully connected layer\n",
        "    Y = torch.matmul(K, X)\n",
        "    return Y.reshape((c_o, h, w))"
      ],
      "metadata": {
        "id": "01AX6TzuWFwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55082aef"
      },
      "source": [
        "Let's explain the `corr2d_multi_in_out_1x1` function:\n",
        "\n",
        "This function is a special case that implements a **1x1 convolutional layer** (also known as a Network in Network layer). A 1x1 convolution is essentially a fully connected layer applied independently to each pixel location across all input channels. This function showcases how this can be achieved efficiently using matrix multiplication.\n",
        "\n",
        "**Function Definition:**\n",
        "```python\n",
        "def corr2d_multi_in_out_1x1(X, K):\n",
        "    c_i, h, w = X.shape\n",
        "    c_o = K.shape[0]\n",
        "    X = X.reshape((c_i, h * w))\n",
        "    K = K.reshape((c_o, c_i))\n",
        "    # Matrix multiplication in the fully connected layer\n",
        "    Y = torch.matmul(K, X)\n",
        "    return Y.reshape((c_o, h, w))\n",
        "```\n",
        "\n",
        "**Assumptions about `X` and `K`:**\n",
        "\n",
        "*   **Input `X`:** This is your input tensor with multiple input channels. Its shape is `(num_input_channels, height, width)`, which is `(c_i, h, w)` in the code.\n",
        "    *   Example: `X` with shape `(3, 3, 3)` means `c_i=3`, `h=3`, `w=3`.\n",
        "\n",
        "*   **Kernel `K`:** This is your 1x1 convolution kernel. Its shape is `(num_output_channels, num_input_channels, 1, 1)`, which is `(c_o, c_i, 1, 1)` in the code.\n",
        "    *   Example: `K` with shape `(2, 3, 1, 1)` means `c_o=2`, `c_i=3`.\n",
        "\n",
        "**Step-by-Step Breakdown:**\n",
        "\n",
        "1.  **Extract Dimensions:**\n",
        "    *   `c_i, h, w = X.shape`: Gets the input channels, height, and width of `X`.\n",
        "    *   `c_o = K.shape[0]`: Gets the number of output channels from the first dimension of `K`.\n",
        "\n",
        "2.  **Reshape Input `X`:**\n",
        "    *   `X = X.reshape((c_i, h * w))`: The input `X` is reshaped from `(c_i, h, w)` to `(c_i, h * w)`. This flattens the spatial dimensions (height and width) into a single dimension. Each column in this new `X` represents all input channel values for a single pixel location.\n",
        "        *   Example: `X` `(3, 3, 3)` becomes `(3, 9)`. This means 3 input channels, and 9 pixel locations. Each column `[:, j]` contains the 3 input channel values for pixel `j`.\n",
        "\n",
        "3.  **Reshape Kernel `K`:**\n",
        "    *   `K = K.reshape((c_o, c_i))`: The kernel `K` is reshaped from `(c_o, c_i, 1, 1)` to `(c_o, c_i)`. Since it's a 1x1 kernel, the `1, 1` dimensions are redundant for the matrix multiplication, and it effectively becomes a weight matrix where rows are output channels and columns are input channels.\n",
        "        *   Example: `K` `(2, 3, 1, 1)` becomes `(2, 3)`. This means 2 output channels, and for each, 3 weights corresponding to the 3 input channels.\n",
        "\n",
        "4.  **Matrix Multiplication:**\n",
        "    *   `Y = torch.matmul(K, X)`: This is the core operation. It performs a matrix multiplication between the reshaped `K` and `X`.\n",
        "        *   `K` has shape `(c_o, c_i)`.\n",
        "        *   `X` has shape `(c_i, h * w)`.\n",
        "        *   The result `Y` will have shape `(c_o, h * w)`.\n",
        "    *   Conceptually, for each pixel location `j` (column in `X`), the `c_i` input channel values are multiplied by the `(c_o, c_i)` weight matrix `K`. This produces `c_o` output channel values for that single pixel location `j`. This is exactly what a 1x1 convolution does: it applies a linear transformation across the channel dimension independently for each spatial location.\n",
        "\n",
        "5.  **Reshape Output `Y`:**\n",
        "    *   `return Y.reshape((c_o, h, w))`: The result `Y` is reshaped back from `(c_o, h * w)` to `(c_o, h, w)`. This restores the spatial dimensions, giving you the final output feature map with `c_o` output channels.\n",
        "        *   Example: `Y` `(2, 9)` becomes `(2, 3, 3)`.\n",
        "\n",
        "**In Summary:** The `corr2d_multi_in_out_1x1` function efficiently implements a 1x1 convolution by transforming the input and kernel into 2D matrices, performing a single matrix multiplication, and then reshaping the result back into a multi-channel image-like format. This highlights the close relationship between 1x1 convolutions and fully connected layers."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of X is (3, 3, 3). This means it has 3 input channels, a height of 3, and a width of 3.\n",
        "The shape of K is (2, 3, 1, 1). This means it is designed to produce 2 output channels, processes 3 input channels, and each individual kernel has a height of 1 and a width of 1 (a 1x1 convolution)."
      ],
      "metadata": {
        "id": "Vc38xDrEcRJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.normal(0, 1, (3, 3, 3))\n",
        "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
        "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
        "Y2 = corr2d_multi_in_out(X, K)\n",
        "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
      ],
      "metadata": {
        "id": "Mia8_5ssWW31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximum and Average pooling"
      ],
      "metadata": {
        "id": "gqARy117hvZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pool2d(X, pool_size, mode='max'):\n",
        "    p_h, p_w = pool_size\n",
        "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            if mode == 'max':\n",
        "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
        "            elif mode == 'avg':\n",
        "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
        "    return Y"
      ],
      "metadata": {
        "id": "dDcYbZNThy4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc3d3a69"
      },
      "source": [
        "Let's break down the line `Y[i, j] = X[i: i + p_h, j: j + p_w].max()`:\n",
        "\n",
        "This line is responsible for performing the \"max pooling\" operation. It calculates the maximum value within a sliding window of the input `X` and assigns that maximum value to a corresponding position in the output `Y`.\n",
        "\n",
        "Let's use the example from your last executed code block:\n",
        "`X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])`\n",
        "`pool_size = (p_h, p_w) = (2, 2)`\n",
        "\n",
        "And let's consider the first iteration where `i=0` and `j=0`.\n",
        "\n",
        "1.  **`X[i: i + p_h, j: j + p_w]`**: This is a tensor slicing operation.\n",
        "    *   `i: i + p_h` becomes `0: 0 + 2`, which is `0:2`. This selects rows from index 0 up to (but not including) index 2.\n",
        "    *   `j: j + p_w` becomes `0: 0 + 2`, which is `0:2`. This selects columns from index 0 up to (but not including) index 2.\n",
        "\n",
        "    So, `X[0:2, 0:2]` selects the top-left `2x2` sub-region (or \"window\") from `X`:\n",
        "    ```\n",
        "    [[0.0, 1.0],\n",
        "     [3.0, 4.0]]\n",
        "    ```\n",
        "\n",
        "2.  **`.max()`**: This method is called on the selected sub-tensor. It returns the single maximum value found within that window.\n",
        "    *   For the window `[[0.0, 1.0], [3.0, 4.0]]`, the maximum value is `4.0`.\n",
        "\n",
        "3.  **`Y[i, j] = ...`**: This assigns the result of the `.max()` operation to the corresponding `(i, j)` position in the output tensor `Y`.\n",
        "    *   So, `Y[0, 0]` will be assigned the value `4.0`.\n",
        "\n",
        "### Let's look at the next step (`i=0, j=1`):\n",
        "\n",
        "1.  **`X[0: 0 + 2, 1: 1 + 2]`** becomes `X[0:2, 1:3]`. This selects the next `2x2` window:\n",
        "    ```\n",
        "    [[1.0, 2.0],\n",
        "     [4.0, 5.0]]\n",
        "    ```\n",
        "\n",
        "2.  **`.max()`**: The maximum value in this window `[[1.0, 2.0], [4.0, 5.0]]` is `5.0`.\n",
        "\n",
        "3.  **`Y[0, 1] = ...`**: So, `Y[0, 1]` will be assigned the value `5.0`.\n",
        "\n",
        "This process continues for all possible `(i, j)` positions in the output tensor `Y`, effectively sliding the `2x2` window across `X` and picking the maximum value within each window."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "pool2d(X, (2, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNYHjt6Qh7r7",
        "outputId": "6d76278e-f042-4bb5-e78a-98ffe851187f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 5.],\n",
              "        [7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d(X, (2, 2), 'avg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeg3BMQNh_8L",
        "outputId": "30ad8ac5-3023-4849-f316-17004af588d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCA-nAupjL5h",
        "outputId": "86a32868-4962-4837-c963-e334ca5acd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  1.,  2.,  3.],\n",
              "          [ 4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11.],\n",
              "          [12., 13., 14., 15.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d = nn.MaxPool2d(3)\n",
        "# Pooling has no model parameters, hence it needs no initialization\n",
        "pool2d(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkCfbJWEj81n",
        "outputId": "ab858c3a-325d-479a-a68b-cc867c2553ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[10.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "pool2d(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOvW3VGmkdsG",
        "outputId": "aaead622-9b55-4351-f0db-0fcf13cab855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59d9cbaf"
      },
      "source": [
        "Let's explain how the output `tensor([[[ 5.,  7.], [13., 15.]]])` is obtained from the last executed code block with `nn.MaxPool2d`.\n",
        "\n",
        "First, let's recall the input `X` and the `nn.MaxPool2d` parameters:\n",
        "\n",
        "*   **Input `X` (shape `(1, 1, 4, 4)`):**\n",
        "    ```\n",
        "    [[[[\n",
        "        0.,  1.,  2.,  3.],\n",
        "        4.,  5.,  6.,  7.],\n",
        "        8.,  9., 10., 11.],\n",
        "        12., 13., 14., 15.]]]\n",
        "    ```\n",
        "\n",
        "*   **Pooling Parameters:**\n",
        "    *   `kernel_size=3`: The pooling window will be `3x3`.\n",
        "    *   `padding=1`: One row/column of padding (zeros by default for `nn.MaxPool2d`) is added around the input.\n",
        "    *   `stride=2`: The pooling window moves 2 steps horizontally and 2 steps vertically.\n",
        "\n",
        "### **Step 1: Apply Padding to Input `X`**\n",
        "\n",
        "With `padding=1`, the `4x4` input `X` becomes a `6x6` padded input (adding zeros around the border):\n",
        "\n",
        "```\n",
        "Padded X:\n",
        "0  0  0  0  0  0\n",
        "0  0  1  2  3  0\n",
        "0  4  5  6  7  0\n",
        "0  8  9 10 11  0\n",
        "0 12 13 14 15  0\n",
        "0  0  0  0  0  0\n",
        "```\n",
        "\n",
        "### **Step 2: Calculate Output Dimensions**\n",
        "\n",
        "The output dimensions can be calculated using the formula:\n",
        "`Output Size = floor((Input Size + 2 * Padding - Kernel Size) / Stride) + 1`\n",
        "\n",
        "For our `4x4` input and `3x3` kernel with `padding=1` and `stride=2`:\n",
        "*   **Height:** `floor((4 + 2*1 - 3) / 2) + 1 = floor(3 / 2) + 1 = floor(1.5) + 1 = 1 + 1 = 2`\n",
        "*   **Width:** `floor((4 + 2*1 - 3) / 2) + 1 = floor(3 / 2) + 1 = floor(1.5) + 1 = 1 + 1 = 2`\n",
        "\n",
        "So, the output feature map will be `2x2`.\n",
        "\n",
        "### **Step 3: Sliding the `3x3` Window and Taking the Maximum**\n",
        "\n",
        "Now, let's see how each element of the `2x2` output is derived from the padded input `X`.\n",
        "\n",
        "1.  **Output Element (0, 0): Value `5`**\n",
        "    *   The `3x3` window starts at `(0,0)` of the padded input.\n",
        "    *   The window covers: `X_padded[0:3, 0:3]`\n",
        "    ```\n",
        "    0  0  0\n",
        "    0  0  1\n",
        "    0  4  5\n",
        "    ```\n",
        "    *   The maximum value in this window is `5`.\n",
        "\n",
        "2.  **Output Element (0, 1): Value `7`**\n",
        "    *   Due to `stride=2`, the window moves 2 steps to the right, starting at `(0,2)` of the padded input.\n",
        "    *   The window covers: `X_padded[0:3, 2:5]`\n",
        "    ```\n",
        "    0  0  0\n",
        "    1  2  3\n",
        "    5  6  7\n",
        "    ```\n",
        "    *   The maximum value in this window is `7`.\n",
        "\n",
        "3.  **Output Element (1, 0): Value `13`**\n",
        "    *   Due to `stride=2`, the window moves 2 steps down and back to column `0`, starting at `(2,0)` of the padded input.\n",
        "    *   The window covers: `X_padded[2:5, 0:3]`\n",
        "    ```\n",
        "    0  4  5\n",
        "    0  8  9\n",
        "    0 12 13\n",
        "    ```\n",
        "    *   The maximum value in this window is `13`.\n",
        "\n",
        "4.  **Output Element (1, 1): Value `15`**\n",
        "    *   Due to `stride=2`, the window moves 2 steps down and 2 steps right, starting at `(2,2)` of the padded input.\n",
        "    *   The window covers: `X_padded[2:5, 2:5]`\n",
        "    ```\n",
        "    5  6  7\n",
        "    9 10 11\n",
        "    13 14 15\n",
        "    ```\n",
        "    *   The maximum value in this window is `15`.\n",
        "\n",
        "This process results in the output tensor: `[[[ 5.,  7.], [13., 15.]]]`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
        "pool2d(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c94wBi_mTy4",
        "outputId": "53580973-ed97-4ef9-8b4e-c193a68cc282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0e3a8dc"
      },
      "source": [
        "Let's explain how the output `tensor([[[ 5.,  7.], [13., 15.]]])` is obtained from the last executed code block with `nn.MaxPool2d`.\n",
        "\n",
        "First, let's recall the input `X` and the `nn.MaxPool2d` parameters:\n",
        "\n",
        "*   **Input `X` (shape `(1, 1, 4, 4)`):**\n",
        "    ```\n",
        "    [[[[\n",
        "        0.,  1.,  2.,  3.],\n",
        "        4.,  5.,  6.,  7.],\n",
        "        8.,  9., 10., 11.],\n",
        "        12., 13., 14., 15.]]]\n",
        "    ```\n",
        "\n",
        "*   **Pooling Parameters:**\n",
        "    *   `kernel_size=(2, 3)`: The pooling window will be `2` rows high and `3` columns wide.\n",
        "    *   `padding=(0, 1)`: No padding on height (0 rows), and one column of padding (zeros by default for `nn.MaxPool2d`) is added on each side of the width.\n",
        "    *   `stride=(2, 3)`: The pooling window moves `2` steps vertically and `3` steps horizontally.\n",
        "\n",
        "### **Step 1: Apply Padding to Input `X`**\n",
        "\n",
        "With `padding=(0, 1)`, the `4x4` input `X` becomes a `4x6` padded input (adding zeros to the left and right of the columns):\n",
        "\n",
        "```\n",
        "Padded X:\n",
        "0  0.  1.  2.  3.  0\n",
        "0  4.  5.  6.  7.  0\n",
        "0  8.  9. 10. 11.  0\n",
        "0 12. 13. 14. 15.  0\n",
        "```\n",
        "\n",
        "### **Step 2: Calculate Output Dimensions**\n",
        "\n",
        "The output dimensions can be calculated using the formula:\n",
        "`Output Size = floor((Input Size + 2 * Padding - Kernel Size) / Stride) + 1`\n",
        "\n",
        "For our `4x4` input `X`, `kernel_size=(2, 3)`, `padding=(0, 1)`, and `stride=(2, 3)`:\n",
        "\n",
        "*   **Height:** `floor((Input Height + 2 * Padding Height - Kernel Height) / Stride Height) + 1`\n",
        "    `floor((4 + 2 * 0 - 2) / 2) + 1 = floor((4 - 2) / 2) + 1 = floor(2 / 2) + 1 = 1 + 1 = 2`\n",
        "\n",
        "*   **Width:** `floor((Input Width + 2 * Padding Width - Kernel Width) / Stride Width) + 1`\n",
        "    `floor((4 + 2 * 1 - 3) / 3) + 1 = floor((4 + 2 - 3) / 3) + 1 = floor(3 / 3) + 1 = 1 + 1 = 2`\n",
        "\n",
        "So, the output feature map will be `2x2`.\n",
        "\n",
        "### **Step 3: Sliding the `2x3` Window and Taking the Maximum**\n",
        "\n",
        "Now, let's see how each element of the `2x2` output is derived from the padded input `X`.\n",
        "\n",
        "1.  **Output Element (0, 0): Value `5`**\n",
        "    *   The `2x3` window starts at `(0,0)` of the padded input.\n",
        "    *   The window covers: `X_padded[0:2, 0:3]`\n",
        "    ```\n",
        "    0.  0.  1.\n",
        "    0.  4.  5.\n",
        "    ```\n",
        "    *   The maximum value in this window is `5.`\n",
        "\n",
        "2.  **Output Element (0, 1): Value `7`**\n",
        "    *   Due to `stride=(2, 3)`, the window moves 0 steps down and `3` steps to the right, starting at `(0,3)` of the padded input (the next column for padding is 0, then the actual data starts from index 1, so the window shifts by 3 from index 0).\n",
        "    *   The window covers: `X_padded[0:2, 3:6]`\n",
        "    ```\n",
        "    2.  3.  0\n",
        "    6.  7.  0\n",
        "    ```\n",
        "    *   The maximum value in this window is `7.`\n",
        "\n",
        "3.  **Output Element (1, 0): Value `13`**\n",
        "    *   Due to `stride=(2, 3)`, the window moves `2` steps down and back to column `0`, starting at `(2,0)` of the padded input.\n",
        "    *   The window covers: `X_padded[2:4, 0:3]`\n",
        "    ```\n",
        "    0.  8.  9.\n",
        "    0. 12. 13.\n",
        "    ```\n",
        "    *   The maximum value in this window is `13.`\n",
        "\n",
        "4.  **Output Element (1, 1): Value `15`**\n",
        "    *   Due to `stride=(2, 3)`, the window moves `2` steps down and `3` steps to the right, starting at `(2,3)` of the padded input.\n",
        "    *   The window covers: `X_padded[2:4, 3:6]`\n",
        "    ```\n",
        "    10. 11.  0\n",
        "    14. 15.  0\n",
        "    ```\n",
        "    *   The maximum value in this window is `15.`\n",
        "\n",
        "This process results in the output tensor: `[[[ 5.,  7.], [13., 15.]]]`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Channels"
      ],
      "metadata": {
        "id": "BDgi3wRpngin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.cat((X, X + 1), 1)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl1CDbEMnicQ",
        "outputId": "63851df5-950e-49f2-9e26-bd6e1bff04e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  1.,  2.,  3.],\n",
              "          [ 4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11.],\n",
              "          [12., 13., 14., 15.]],\n",
              "\n",
              "         [[ 1.,  2.,  3.,  4.],\n",
              "          [ 5.,  6.,  7.,  8.],\n",
              "          [ 9., 10., 11., 12.],\n",
              "          [13., 14., 15., 16.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "pool2d(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WlrICTQnqJH",
        "outputId": "a7d26385-b9a4-44f7-b2ae-300f66dd2727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]],\n",
              "\n",
              "         [[ 6.,  8.],\n",
              "          [14., 16.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Network"
      ],
      "metadata": {
        "id": "V3jWnCAYsILg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_cnn(module):\n",
        "    \"\"\"Initialize weights for CNNs.\"\"\"\n",
        "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
        "        nn.init.xavier_uniform_(module.weight)\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    \"\"\"The LeNet-5 model.\"\"\"\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), nn.Sigmoid(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(120), nn.Sigmoid(),\n",
        "            nn.LazyLinear(84), nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes))\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.net(X)\n",
        "\n",
        "    def layer_summary(self, X_shape):\n",
        "        X = torch.randn(*X_shape)\n",
        "        for layer in self.net:\n",
        "            X = layer(X)\n",
        "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
        "\n",
        "model = LeNet()\n",
        "model.layer_summary((1, 1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hR4PQxGsO8O",
        "outputId": "666faefa-5956-48b0-8469-25f0327021e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([1, 6, 28, 28])\n",
            "Sigmoid output shape:\t torch.Size([1, 6, 28, 28])\n",
            "AvgPool2d output shape:\t torch.Size([1, 6, 14, 14])\n",
            "Conv2d output shape:\t torch.Size([1, 16, 10, 10])\n",
            "Sigmoid output shape:\t torch.Size([1, 16, 10, 10])\n",
            "AvgPool2d output shape:\t torch.Size([1, 16, 5, 5])\n",
            "Flatten output shape:\t torch.Size([1, 400])\n",
            "Linear output shape:\t torch.Size([1, 120])\n",
            "Sigmoid output shape:\t torch.Size([1, 120])\n",
            "Linear output shape:\t torch.Size([1, 84])\n",
            "Sigmoid output shape:\t torch.Size([1, 84])\n",
            "Linear output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "540d1923",
        "outputId": "db8174de-0a5a-450f-f3f1-81d55953fefd"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils import data\n",
        "\n",
        "# 2. Define a transforms.Compose object named trans\n",
        "trans = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.1307], std=[0.3081]) # Standard normalization for FashionMNIST\n",
        "])\n",
        "\n",
        "# 3. Download and load the FashionMNIST training dataset\n",
        "mnist_train = torchvision.datasets.FashionMNIST(\n",
        "    root=\"./data\", train=True, transform=trans, download=True\n",
        ")\n",
        "\n",
        "# 4. Download and load the FashionMNIST testing dataset\n",
        "mnist_test = torchvision.datasets.FashionMNIST(\n",
        "    root=\"./data\", train=False, transform=trans, download=True\n",
        ")\n",
        "\n",
        "# 5. Define the batch_size\n",
        "batch_size = 256\n",
        "\n",
        "# 6. Create a DataLoader for the training dataset\n",
        "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "# 7. Create a DataLoader for the testing dataset\n",
        "test_iter = data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52f65e5a"
      },
      "source": [
        "model = LeNet(num_classes=10)\n",
        "model.apply(init_cnn)\n",
        "loss = nn.CrossEntropyLoss(reduction='none')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "717a73f4"
      },
      "source": [
        "def train_batch(model, X, y, loss):\n",
        "    # 1. Perform a forward pass\n",
        "    y_hat = model(X)\n",
        "    # 2. Calculate the loss\n",
        "    l = loss(y_hat, y)\n",
        "    return y_hat, l\n",
        "\n",
        "def accuracy(y_hat, y):\n",
        "    # 3. Calculate accuracy by comparing predictions with true labels\n",
        "    # y_hat is logits, y is true labels\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1)\n",
        "    cmp = (y_hat.type(y.dtype) == y)\n",
        "    return float(cmp.type(torch.float32).sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7884eecb"
      },
      "source": [
        "import torch # Import torch if not already imported in this scope\n",
        "\n",
        "def train_epoch(model, train_iter, loss, optimizer):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    # Initialize metrics for the epoch\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Iterate through the training data loader\n",
        "    for X, y in train_iter:\n",
        "        # 5a. Perform a forward pass and calculate the loss\n",
        "        y_hat, l = train_batch(model, X, y, loss)\n",
        "\n",
        "        # 5b. Zero out the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 5c. Perform a backward pass\n",
        "        l.sum().backward()\n",
        "\n",
        "        # 5d. Update the model's weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # 5e. Accumulate the total loss and correct predictions\n",
        "        total_loss += l.sum().item() # .item() to get scalar from tensor\n",
        "        total_correct += accuracy(y_hat, y)\n",
        "        total_samples += y.numel()\n",
        "\n",
        "    # 6. Calculate and return the average training loss and accuracy\n",
        "    avg_loss = total_loss / total_samples\n",
        "    avg_accuracy = total_correct / total_samples\n",
        "    return avg_loss, avg_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9f5d613"
      },
      "source": [
        "def evaluate_accuracy(model, data_iter):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    # Initialize variables to accumulate metrics\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Disable gradient computation for evaluation\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            # Perform a forward pass\n",
        "            y_hat = model(X)\n",
        "            # Calculate the number of correct predictions\n",
        "            total_correct += accuracy(y_hat, y)\n",
        "            total_samples += y.numel()\n",
        "\n",
        "    # Return the overall accuracy\n",
        "    return total_correct / total_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  print(train_epoch(model, train_iter, loss, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUiaOfKf4CZ4",
        "outputId": "6bd8b647-c4e9-40f0-8b57-0d075e1fb418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2.31896084874471, 0.1012)\n",
            "(1.5896739673614502, 0.3494833333333333)\n",
            "(0.8661880306243896, 0.6575666666666666)\n",
            "(0.6667089829762777, 0.7402166666666666)\n",
            "(0.5766110443115234, 0.7755833333333333)\n",
            "(0.4986470890045166, 0.8130166666666667)\n",
            "(0.4615550043106079, 0.8281166666666666)\n",
            "(0.431716061147054, 0.8409333333333333)\n",
            "(0.4122020723660787, 0.84845)\n",
            "(0.38354802646636965, 0.8576333333333334)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_accuracy(model, test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vohwDrruv-rf",
        "outputId": "e5e0783d-f4cb-4e17-f8cd-37219cf811be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8602"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_PyTorch/blob/main/LinearNeuralNetworkForRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "gzRdY8Aj6-5U"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD():\n",
        "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
        "    def __init__(self, params, lr):\n",
        "        self.params = params\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self):\n",
        "        for param in self.params:\n",
        "            # Ensure param.grad is not None before performing operation\n",
        "            if param.grad is not None:\n",
        "                param.data -= self.lr * param.grad\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for param in self.params:\n",
        "            if param.grad is not None:\n",
        "                param.grad.zero_()"
      ],
      "metadata": {
        "id": "oaLOnWGDhGMd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e1cd391"
      },
      "source": [
        "class LinearRegressionScratch(nn.Module):\n",
        "    \"\"\"The linear regression model implemented from scratch.\"\"\"\n",
        "    def __init__(self, num_inputs, lr, sigma=0.01):\n",
        "        super().__init__()\n",
        "        self.lr = lr # Store lr as an instance attribute\n",
        "        self.w = torch.normal(0, sigma, (num_inputs, 1), requires_grad=True)\n",
        "        self.b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "      return torch.matmul(X, self.w) + self.b\n",
        "\n",
        "    def loss(self, y_hat, y):\n",
        "      l = (y_hat-y)**2 / 2\n",
        "      return l.mean()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      return SGD([self.w, self.b], self.lr)\n",
        "\n",
        "    def prepare_batch(self, batch):\n",
        "      return batch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62e49dd8"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "# 1. Define the true weight vector w and bias b\n",
        "true_w = torch.tensor([2, -3.4]).reshape(-1, 1)\n",
        "true_b = torch.tensor([4.2])\n",
        "\n",
        "# Define dataset parameters\n",
        "num_samples = 1000\n",
        "num_features = 2\n",
        "batch_size = 32\n",
        "\n",
        "# 2. Generate a synthetic dataset X of features and y of labels\n",
        "X = torch.randn(num_samples, num_features)\n",
        "y = torch.matmul(X, true_w) + true_b + torch.randn(num_samples, 1) * 0.01\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a798bc0"
      },
      "source": [
        "dataset = TensorDataset(X, y)\n",
        "\n",
        "# 4. Split the TensorDataset into training and validation sets\n",
        "train_size = int(0.8 * num_samples)\n",
        "val_size = num_samples - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# 5. Create DataLoader instances for both the training and validation sets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8567f678"
      },
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_dataloader, val_dataloader=None, max_epochs=10):\n",
        "        self.model = model\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.val_dataloader = val_dataloader\n",
        "        self.max_epochs = max_epochs\n",
        "        self.optim = model.configure_optimizers()\n",
        "\n",
        "    def fit(self):\n",
        "        for epoch in range(self.max_epochs):\n",
        "            self.model.train()\n",
        "            total_train_loss = 0\n",
        "            for X, y in self.train_dataloader:\n",
        "                # Forward pass\n",
        "                y_hat = self.model(X)\n",
        "                # Calculate loss\n",
        "                loss = self.model.loss(y_hat, y)\n",
        "\n",
        "                # Backpropagation\n",
        "                self.optim.zero_grad()\n",
        "                loss.backward()\n",
        "                # Optimization step\n",
        "                self.optim.step()\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = total_train_loss / len(self.train_dataloader)\n",
        "            print(f\"Epoch {epoch + 1}/{self.max_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "            # Validation loop (optional)\n",
        "            if self.val_dataloader is not None:\n",
        "                self.model.eval()\n",
        "                total_val_loss = 0\n",
        "                with torch.no_grad():\n",
        "                    for X_val, y_val in self.val_dataloader:\n",
        "                        y_hat_val = self.model(X_val)\n",
        "                        val_loss = self.model.loss(y_hat_val, y_val)\n",
        "                        total_val_loss += val_loss.item()\n",
        "                avg_val_loss = total_val_loss / len(self.val_dataloader)\n",
        "                print(f\"Epoch {epoch + 1}/{self.max_epochs}, Validation Loss: {avg_val_loss:.4f}\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba399052"
      },
      "source": [
        "model = LinearRegressionScratch(num_features, lr=0.03)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3742400b"
      },
      "source": [
        "max_epochs = 10\n",
        "trainer = Trainer(model, train_dataloader, val_dataloader, max_epochs=max_epochs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee9a0b02",
        "outputId": "d0f6d791-7b54-4222-d755-7ef1ecdf25b4"
      },
      "source": [
        "trainer.fit()\n",
        "print(\"Model training initiated.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 8.7349\n",
            "Epoch 1/10, Validation Loss: 3.9119\n",
            "Epoch 2/10, Training Loss: 1.9573\n",
            "Epoch 2/10, Validation Loss: 0.8767\n",
            "Epoch 3/10, Training Loss: 0.4397\n",
            "Epoch 3/10, Validation Loss: 0.1968\n",
            "Epoch 4/10, Training Loss: 0.0988\n",
            "Epoch 4/10, Validation Loss: 0.0443\n",
            "Epoch 5/10, Training Loss: 0.0224\n",
            "Epoch 5/10, Validation Loss: 0.0100\n",
            "Epoch 6/10, Training Loss: 0.0051\n",
            "Epoch 6/10, Validation Loss: 0.0023\n",
            "Epoch 7/10, Training Loss: 0.0012\n",
            "Epoch 7/10, Validation Loss: 0.0005\n",
            "Epoch 8/10, Training Loss: 0.0003\n",
            "Epoch 8/10, Validation Loss: 0.0002\n",
            "Epoch 9/10, Training Loss: 0.0001\n",
            "Epoch 9/10, Validation Loss: 0.0001\n",
            "Epoch 10/10, Training Loss: 0.0001\n",
            "Epoch 10/10, Validation Loss: 0.0001\n",
            "Model training initiated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With nn.Parameter()"
      ],
      "metadata": {
        "id": "EvwXrwg5gPCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "a1kCBLEBgTHQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionScratch(nn.Module):\n",
        "    \"\"\"The linear regression model implemented from scratch.\"\"\"\n",
        "    def __init__(self, num_inputs, lr, sigma=0.01):\n",
        "        super().__init__()\n",
        "        self.lr = lr # Store lr as an instance attribute\n",
        "        self.w = nn.Parameter(torch.normal(0, sigma, (num_inputs, 1))) # Wrapped in nn.Parameter\n",
        "        self.b = nn.Parameter(torch.zeros(1)) # Wrapped in nn.Parameter\n",
        "\n",
        "    def forward(self, X):\n",
        "      return torch.matmul(X, self.w) + self.b"
      ],
      "metadata": {
        "id": "n289vtdkgbHI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "# 1. Define the true weight vector w and bias b\n",
        "true_w = torch.tensor([2, -3.4]).reshape(-1, 1)\n",
        "true_b = torch.tensor([4.2])\n",
        "\n",
        "# Define dataset parameters\n",
        "num_samples = 1000\n",
        "num_features = 2\n",
        "batch_size = 32\n",
        "\n",
        "# 2. Generate a synthetic dataset X of features and y of labels\n",
        "X = torch.randn(num_samples, num_features)\n",
        "y = torch.matmul(X, true_w) + true_b + torch.randn(num_samples, 1) * 0.01"
      ],
      "metadata": {
        "id": "XzrcE8dVgilk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size,shuffle = True)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle = False)"
      ],
      "metadata": {
        "id": "sivcD1bEgmg6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegressionScratch(num_features, 0.001)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "OMD9d9fYgqX3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for inputs, targets in train_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "id": "-4NfJZ1ugtvL",
        "outputId": "2db88fe4-dd09-498e-ea82-1e3860483b26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 31.4040\n",
            "Epoch [2/50], Loss: 30.9956\n",
            "Epoch [3/50], Loss: 30.5858\n",
            "Epoch [4/50], Loss: 30.1758\n",
            "Epoch [5/50], Loss: 29.7718\n",
            "Epoch [6/50], Loss: 29.3684\n",
            "Epoch [7/50], Loss: 28.9691\n",
            "Epoch [8/50], Loss: 28.5788\n",
            "Epoch [9/50], Loss: 28.1840\n",
            "Epoch [10/50], Loss: 27.8016\n",
            "Epoch [11/50], Loss: 27.4224\n",
            "Epoch [12/50], Loss: 27.0438\n",
            "Epoch [13/50], Loss: 26.6698\n",
            "Epoch [14/50], Loss: 26.3024\n",
            "Epoch [15/50], Loss: 25.9401\n",
            "Epoch [16/50], Loss: 25.5750\n",
            "Epoch [17/50], Loss: 25.2224\n",
            "Epoch [18/50], Loss: 24.8688\n",
            "Epoch [19/50], Loss: 24.5168\n",
            "Epoch [20/50], Loss: 24.1754\n",
            "Epoch [21/50], Loss: 23.8332\n",
            "Epoch [22/50], Loss: 23.4995\n",
            "Epoch [23/50], Loss: 23.1607\n",
            "Epoch [24/50], Loss: 22.8324\n",
            "Epoch [25/50], Loss: 22.5071\n",
            "Epoch [26/50], Loss: 22.1812\n",
            "Epoch [27/50], Loss: 21.8636\n",
            "Epoch [28/50], Loss: 21.5469\n",
            "Epoch [29/50], Loss: 21.2357\n",
            "Epoch [30/50], Loss: 20.9246\n",
            "Epoch [31/50], Loss: 20.6211\n",
            "Epoch [32/50], Loss: 20.3185\n",
            "Epoch [33/50], Loss: 20.0210\n",
            "Epoch [34/50], Loss: 19.7206\n",
            "Epoch [35/50], Loss: 19.4326\n",
            "Epoch [36/50], Loss: 19.1455\n",
            "Epoch [37/50], Loss: 18.8556\n",
            "Epoch [38/50], Loss: 18.5762\n",
            "Epoch [39/50], Loss: 18.2970\n",
            "Epoch [40/50], Loss: 18.0186\n",
            "Epoch [41/50], Loss: 17.7484\n",
            "Epoch [42/50], Loss: 17.4750\n",
            "Epoch [43/50], Loss: 17.2122\n",
            "Epoch [44/50], Loss: 16.9459\n",
            "Epoch [45/50], Loss: 16.6857\n",
            "Epoch [46/50], Loss: 16.4303\n",
            "Epoch [47/50], Loss: 16.1706\n",
            "Epoch [48/50], Loss: 15.9210\n",
            "Epoch [49/50], Loss: 15.6716\n",
            "Epoch [50/50], Loss: 15.4269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegresson(nn.Module):\n",
        "  def __init__(self, number_inputs):\n",
        "    super().__init__()\n",
        "    self.w = nn.Linear(in_features=number_inputs, out_features = 1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.w(X)"
      ],
      "metadata": {
        "id": "CEPUo9jGVaUg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegresson(num_features)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "nYDIBKKjVdoG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for inputs, targets in train_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "id": "op5FRC11Vdkn",
        "outputId": "ae18130c-d4cd-4f22-8d61-5f82aa3a2426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 31.8182\n",
            "Epoch [2/50], Loss: 31.3898\n",
            "Epoch [3/50], Loss: 30.9763\n",
            "Epoch [4/50], Loss: 30.5526\n",
            "Epoch [5/50], Loss: 30.1455\n",
            "Epoch [6/50], Loss: 29.7474\n",
            "Epoch [7/50], Loss: 29.3381\n",
            "Epoch [8/50], Loss: 28.9439\n",
            "Epoch [9/50], Loss: 28.5492\n",
            "Epoch [10/50], Loss: 28.1651\n",
            "Epoch [11/50], Loss: 27.7800\n",
            "Epoch [12/50], Loss: 27.3959\n",
            "Epoch [13/50], Loss: 27.0255\n",
            "Epoch [14/50], Loss: 26.6525\n",
            "Epoch [15/50], Loss: 26.2807\n",
            "Epoch [16/50], Loss: 25.9205\n",
            "Epoch [17/50], Loss: 25.5619\n",
            "Epoch [18/50], Loss: 25.2042\n",
            "Epoch [19/50], Loss: 24.8511\n",
            "Epoch [20/50], Loss: 24.5022\n",
            "Epoch [21/50], Loss: 24.1585\n",
            "Epoch [22/50], Loss: 23.8149\n",
            "Epoch [23/50], Loss: 23.4812\n",
            "Epoch [24/50], Loss: 23.1456\n",
            "Epoch [25/50], Loss: 22.8156\n",
            "Epoch [26/50], Loss: 22.4867\n",
            "Epoch [27/50], Loss: 22.1655\n",
            "Epoch [28/50], Loss: 21.8468\n",
            "Epoch [29/50], Loss: 21.5261\n",
            "Epoch [30/50], Loss: 21.2196\n",
            "Epoch [31/50], Loss: 20.9056\n",
            "Epoch [32/50], Loss: 20.6028\n",
            "Epoch [33/50], Loss: 20.2999\n",
            "Epoch [34/50], Loss: 20.0015\n",
            "Epoch [35/50], Loss: 19.7012\n",
            "Epoch [36/50], Loss: 19.4172\n",
            "Epoch [37/50], Loss: 19.1232\n",
            "Epoch [38/50], Loss: 18.8372\n",
            "Epoch [39/50], Loss: 18.5549\n",
            "Epoch [40/50], Loss: 18.2759\n",
            "Epoch [41/50], Loss: 17.9980\n",
            "Epoch [42/50], Loss: 17.7294\n",
            "Epoch [43/50], Loss: 17.4549\n",
            "Epoch [44/50], Loss: 17.1894\n",
            "Epoch [45/50], Loss: 16.9275\n",
            "Epoch [46/50], Loss: 16.6671\n",
            "Epoch [47/50], Loss: 16.4067\n",
            "Epoch [48/50], Loss: 16.1544\n",
            "Epoch [49/50], Loss: 15.9014\n",
            "Epoch [50/50], Loss: 15.6520\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_PyTorch/blob/main/GatedRecurrentUnitNetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "# Load the IMDB dataset\n",
        "max_features = 5000\n",
        "max_len = 500\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
      ],
      "metadata": {
        "id": "fxMU9g6sjem0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to ensure uniform length\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "x_train = torch.tensor(x_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "x_test = torch.tensor(x_test, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "CEKv8qiejiFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(x_train, y_train)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_data = TensorDataset(x_test, y_test)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "lUR8y9E6jltu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.gru(x)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Model hyperparameters\n",
        "vocab_size = max_features\n",
        "embedding_dim = 128\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "num_layers = 3\n",
        "\n",
        "# Initialize the model, criterion and optimizer\n",
        "gru_model = GRUModel(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "5si9LR4Cjsgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    gru_model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = gru_model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "id": "GdfRWkOajxI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "gru_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = gru_model(inputs)\n",
        "        predicted = (outputs.squeeze() >= 0.5).float()\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "mANqd94sj4UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Input-to-hidden\n",
        "        self.W_z = nn.Parameter(torch.randn(hidden_size, input_size) * 0.01)\n",
        "        self.W_r = nn.Parameter(torch.randn(hidden_size, input_size) * 0.01)\n",
        "        self.W_h = nn.Parameter(torch.randn(hidden_size, input_size) * 0.01)\n",
        "\n",
        "        # Hidden-to-hidden\n",
        "        self.U_z = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01)\n",
        "        self.U_r = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01)\n",
        "        self.U_h = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01)\n",
        "\n",
        "        # Biases\n",
        "        self.b_z = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.b_r = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.b_h = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "    def forward(self, x_t, h_prev):\n",
        "        # x_t: (batch, input_size)\n",
        "        # h_prev: (batch, hidden_size)\n",
        "\n",
        "        z_t = torch.sigmoid(\n",
        "            x_t @ self.W_z.T + h_prev @ self.U_z.T + self.b_z\n",
        "        )\n",
        "        r_t = torch.sigmoid(\n",
        "            x_t @ self.W_r.T + h_prev @ self.U_r.T + self.b_r\n",
        "        )\n",
        "\n",
        "        h_tilde = torch.tanh(\n",
        "            x_t @ self.W_h.T + (r_t * h_prev) @ self.U_h.T + self.b_h\n",
        "        )\n",
        "\n",
        "        h_t = (1 - z_t) * h_prev + z_t * h_tilde\n",
        "        return h_t"
      ],
      "metadata": {
        "id": "YAMCBapt18Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.cell = GRUCell(input_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, h0=None):\n",
        "        # x: (batch, seq_len, input_size)\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        if h0 is None:\n",
        "            h_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
        "        else:\n",
        "            h_t = h0\n",
        "\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            x_t = x[:, t, :]          # (batch, input_size)\n",
        "            h_t = self.cell(x_t, h_t) # (batch, hidden_size)\n",
        "            outputs.append(h_t.unsqueeze(1))\n",
        "\n",
        "        # Concatenate over time\n",
        "        outputs = torch.cat(outputs, dim=1)  # (batch, seq_len, hidden_size)\n",
        "        return outputs, h_t"
      ],
      "metadata": {
        "id": "xA5k2R9E1_9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For regression"
      ],
      "metadata": {
        "id": "vou1EXC75a3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def generate_data(batch_size, seq_len, input_size):\n",
        "    # Random input sequences\n",
        "    x = torch.randn(batch_size, seq_len, input_size)\n",
        "\n",
        "    # Target: cumulative sum across time (many-to-many)\n",
        "    y = torch.cumsum(x, dim=1)\n",
        "    return x, y\n",
        "\n",
        "input_size = 5\n",
        "hidden_size = 16\n",
        "seq_len = 20\n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "\n",
        "model = GRU(input_size, hidden_size)\n",
        "output_layer = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(list(model.parameters()) + list(output_layer.parameters()), lr=0.001)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# -----------------------------\n",
        "# Training loop\n",
        "# -----------------------------\n",
        "for epoch in range(epochs):\n",
        "    x, y = generate_data(batch_size, seq_len, input_size)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs, h_last = model(x)          # (batch, seq_len, hidden)\n",
        "    preds = output_layer(outputs)       # (batch, seq_len, input_size)\n",
        "\n",
        "    loss = criterion(preds, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {loss.item():.6f}\")\n"
      ],
      "metadata": {
        "id": "EsEKAUFC3zKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For classification"
      ],
      "metadata": {
        "id": "sBXmkF175eSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def generate_classification_data(batch_size, seq_len, input_size):\n",
        "    x = torch.randn(batch_size, seq_len, input_size)\n",
        "\n",
        "    # Label = 1 if sum > 0, else 0\n",
        "    seq_sum = x.sum(dim=(1, 2))\n",
        "    y = (seq_sum > 0).long()\n",
        "\n",
        "    return x, y\n",
        "\n",
        "input_size = 4\n",
        "hidden_size = 32\n",
        "num_classes = 2\n",
        "seq_len = 15\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "\n",
        "model = GRU(input_size, hidden_size)\n",
        "classifier = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(list(model.parameters()) + list(classifier.parameters()), lr=0.001)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    x, y = generate_classification_data(batch_size, seq_len, input_size)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs, h_last = model(x)     # outputs: (batch, seq_len, hidden)\n",
        "    final_state = outputs[:, -1]   # use last hidden state for classification\n",
        "\n",
        "    logits = classifier(final_state)  # (batch, num_classes)\n",
        "\n",
        "    loss = criterion(logits, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        pred = logits.argmax(dim=1)\n",
        "        acc = (pred == y).float().mean().item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {loss.item():.4f} | Acc: {acc:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "id": "AUl34cXm5d1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "-Mx7srt0AKv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUScratch(nn.Module):\n",
        "    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n",
        "        super().__init__()\n",
        "        # self.save_hyperparameters() # Removed as it's not a standard nn.Module method without d2l\n",
        "        self.num_hiddens = num_hiddens # Store num_hiddens as an instance attribute\n",
        "\n",
        "        init_weight = lambda *shape: nn.Parameter(torch.randn(*shape) * sigma)\n",
        "        triple = lambda: (init_weight(num_inputs, num_hiddens),\n",
        "                          init_weight(num_hiddens, num_hiddens),\n",
        "                          nn.Parameter(torch.zeros(num_hiddens)))\n",
        "        self.W_xz, self.W_hz, self.b_z = triple()  # Update gate\n",
        "        self.W_xr, self.W_hr, self.b_r = triple()  # Reset gate\n",
        "        self.W_xh, self.W_hh, self.b_h = triple()  # Candidate hidden state\n",
        "\n",
        "    def forward(self, inputs, H=None):\n",
        "        if H is None:\n",
        "            # Initial state with shape: (batch_size, num_hiddens)\n",
        "            H = torch.zeros((inputs.shape[1], self.num_hiddens),\n",
        "                          device=inputs.device)\n",
        "        outputs = []\n",
        "        for X in inputs:\n",
        "            Z = torch.sigmoid(torch.matmul(X, self.W_xz) +\n",
        "                            torch.matmul(H, self.W_hz) + self.b_z)\n",
        "            R = torch.sigmoid(torch.matmul(X, self.W_xr) +\n",
        "                            torch.matmul(H, self.W_hr) + self.b_r)\n",
        "            H_tilde = torch.tanh(torch.matmul(X, self.W_xh) +\n",
        "                               torch.matmul(R * H, self.W_hh) + self.b_h)\n",
        "            H = Z * H + (1 - Z) * H_tilde\n",
        "            outputs.append(H)\n",
        "        return outputs, H"
      ],
      "metadata": {
        "id": "t0KqRX2sAYBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, num_inputs, num_hiddens):\n",
        "        super().__init__()\n",
        "        self.rnn = GRUScratch(num_inputs, num_hiddens)\n",
        "        self.fc = nn.Linear(num_hiddens, 1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # X: (batch, seq, input_size)\n",
        "        X = X.permute(1, 0, 2)  # (seq, batch, input)\n",
        "        outputs, _ = self.rnn(X)\n",
        "        outputs = torch.stack(outputs)  # (seq, batch, hidden)\n",
        "        outputs = outputs.permute(1, 0, 2)  # (batch, seq, hidden)\n",
        "        return self.fc(outputs)"
      ],
      "metadata": {
        "id": "s0t9g3M0D8jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import random\n",
        "\n",
        "def generate_data(num_sequences=2000, seq_len=20):\n",
        "    X, Y = [], []\n",
        "    for _ in range(num_sequences):\n",
        "        start = random.random()\n",
        "        seq = [start + i*0.05 for i in range(seq_len+1)]\n",
        "        X.append(seq[:-1])   # first 20 numbers\n",
        "        Y.append(seq[1:])    # shifted by 1\n",
        "    X = torch.tensor(X).float().unsqueeze(-1)  # (batch, seq, 1)\n",
        "    Y = torch.tensor(Y).float().unsqueeze(-1)\n",
        "    return X, Y\n",
        "\n",
        "X, Y = generate_data()\n",
        "print(X.shape, Y.shape)"
      ],
      "metadata": {
        "id": "5cRp-JJDD1bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GRUModel(num_inputs=1, num_hiddens=32)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "batch_size = 32\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    perm = torch.randperm(X.size(0))\n",
        "    total_loss = 0\n",
        "\n",
        "    for i in range(0, X.size(0), batch_size):\n",
        "        idx = perm[i:i+batch_size]\n",
        "        xb, yb = X[idx], Y[idx]\n",
        "\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "id": "bhg29Gx2ECq5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}